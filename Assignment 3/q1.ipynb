{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Student Name: Saeedreza Zouashkiani\n",
    "# Student ID: 400206262"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import os\n",
    "from utils import calculate_metrics, count_parameters, train_model\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "writer = SummaryWriter('runs/q1/fc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the dataset and split into train val and test sets with a ratio of 60:10:30\n",
    "# transform normalize and resize the images to 150*150\n",
    "transform = transforms.Compose([transforms.Resize((150, 150)), transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "dataset = torchvision.datasets.ImageFolder(root='Shoe vs Sandal vs Boot Dataset', transform=transform)\n",
    "train_size = int(0.6 * len(dataset))\n",
    "val_size = int(0.1 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, val_size, test_size])\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(num_images=1, root_dir=\"Shoe vs Sandal vs Boot Dataset\"):\n",
    "    classes = os.listdir(root_dir)\n",
    "    plt.figure(figsize=(len(classes) * 2, num_images * 2))\n",
    "    for i in range(len(classes)):\n",
    "        for j in range(num_images):\n",
    "            # get a random image from the class\n",
    "            img_name = np.random.choice(os.listdir(os.path.join(root_dir, classes[i])))\n",
    "            img_path = os.path.join(root_dir, classes[i], img_name)\n",
    "            img = plt.imread(img_path)\n",
    "            plt.subplot(num_images, len(classes), i * num_images + j + 1)\n",
    "            plt.imshow(img)\n",
    "            plt.title(classes[i])\n",
    "            plt.axis(\"off\")\n",
    "    plt.show()\n",
    "plot_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, hidden_layers):\n",
    "        super(MLP, self).__init__()\n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "        for i in range(len(hidden_layers) - 1):\n",
    "            self.hidden_layers.append(nn.Linear(hidden_layers[i], hidden_layers[i + 1]))\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        for i, linear in enumerate(self.hidden_layers):\n",
    "            if i != len(self.hidden_layers) - 1:\n",
    "                x = F.relu(linear(x))\n",
    "                x = self.dropout(x)\n",
    "            else:\n",
    "                x = self.softmax(linear(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layers = [150 * 150 * 3, 128, 64, 3]\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "fc_model = MLP(hidden_layers).to(device)\n",
    "# add the model to the tensorboard\n",
    "writer.add_graph(fc_model, torch.rand(1, 3, 150, 150).to(device))\n",
    "writer.close()\n",
    "\n",
    "optimizer = optim.Adam(fc_model.parameters(), lr=1e-4)\n",
    "train_loss, val_loss, train_acc, val_acc = train_model(fc_model, train_loader, val_loader,\n",
    "                                                       epochs=10, criterion=criterion, optimizer=optimizer,\n",
    "                                                       writer=writer, device=device, tensorboard=True, verbose=True)\n",
    "# save the model\n",
    "torch.save(fc_model.state_dict(), \"fc_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics for the test set\n",
    "classes = os.listdir(\"Shoe vs Sandal vs Boot Dataset\")\n",
    "print(f'The model has {count_parameters(fc_model):,} trainable parameters')    \n",
    "calculate_metrics(fc_model, test_loader, classes, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DropBlock2d(nn.Module):\n",
    "    r\"\"\"Randomly zeroes 2D spatial blocks of the input tensor.\n",
    "    As described in the paper\n",
    "    `DropBlock: A regularization method for convolutional networks`_ ,\n",
    "    dropping whole blocks of feature map allows to remove semantic\n",
    "    information as compared to regular dropout.\n",
    "    Args:\n",
    "        drop_prob (float): probability of an element to be dropped.\n",
    "        block_size (int): size of the block to drop\n",
    "    Shape:\n",
    "        - Input: `(N, C, H, W)`\n",
    "        - Output: `(N, C, H, W)`\n",
    "    .. _DropBlock: A regularization method for convolutional networks:\n",
    "       https://arxiv.org/abs/1810.12890\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, drop_prob, block_size):\n",
    "        super(DropBlock2d, self).__init__()\n",
    "\n",
    "        self.drop_prob = drop_prob\n",
    "        self.block_size = block_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        # shape: (bsize, channels, height, width)\n",
    "\n",
    "        assert x.dim() == 4, \\\n",
    "            \"Expected input with 4 dimensions (bsize, channels, height, width)\"\n",
    "\n",
    "        if not self.training or self.drop_prob == 0.:\n",
    "            return x\n",
    "        else:\n",
    "            # get gamma value\n",
    "            gamma = self._compute_gamma(x)\n",
    "\n",
    "            # sample mask\n",
    "            mask = (torch.rand(x.shape[0], *x.shape[2:]) < gamma).float()\n",
    "\n",
    "            # place mask on input device\n",
    "            mask = mask.to(x.device)\n",
    "\n",
    "            # compute block mask\n",
    "            block_mask = self._compute_block_mask(mask)\n",
    "\n",
    "            # apply block mask\n",
    "            out = x * block_mask[:, None, :, :]\n",
    "\n",
    "            # scale output\n",
    "            out = out * block_mask.numel() / block_mask.sum()\n",
    "\n",
    "            return out\n",
    "\n",
    "    def _compute_block_mask(self, mask):\n",
    "        block_mask = F.max_pool2d(input=mask[:, None, :, :],\n",
    "                                  kernel_size=(self.block_size, self.block_size),\n",
    "                                  stride=(1, 1),\n",
    "                                  padding=self.block_size // 2)\n",
    "\n",
    "        if self.block_size % 2 == 0:\n",
    "            block_mask = block_mask[:, :, :-1, :-1]\n",
    "\n",
    "        block_mask = 1 - block_mask.squeeze(1)\n",
    "\n",
    "        return block_mask\n",
    "\n",
    "    def _compute_gamma(self, x):\n",
    "        return self.drop_prob / (self.block_size ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, block_dropout=True):\n",
    "        super(CNN, self).__init__()\n",
    "        self.block_dropout = block_dropout\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(64 * 18 * 18, 400)\n",
    "        self.fc2 = nn.Linear(400, 3)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(16)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(32)\n",
    "        self.batchnorm3 = nn.BatchNorm2d(64)\n",
    "        self.batchnorm4 = nn.BatchNorm1d(400)\n",
    "        self.maxpool = nn.MaxPool2d(2, 2)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        if self.block_dropout:\n",
    "            self.dropblock1 = DropBlock2d(0.1, 3)\n",
    "            self.dropblock2 = DropBlock2d(0.1, 3)\n",
    "            self.dropblock3 = DropBlock2d(0.1, 3)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.maxpool(F.relu(self.batchnorm1(self.conv1(x))))\n",
    "        if self.block_dropout:\n",
    "            x = self.dropblock1(x)\n",
    "        else:\n",
    "            x = F.dropout(x, 0.2, training=self.training)\n",
    "        x = self.maxpool(F.relu(self.batchnorm2(self.conv2(x))))\n",
    "        if self.block_dropout:\n",
    "            x = self.dropblock2(x)\n",
    "        else:\n",
    "            x = F.dropout(x, 0.2, training=self.training)\n",
    "        x = self.maxpool(F.relu(self.batchnorm3(self.conv3(x))))\n",
    "        if self.block_dropout:\n",
    "            x =  self.dropblock3(x)\n",
    "        else:\n",
    "            x = F.dropout(x, 0.2, training=self.training)\n",
    "        x = x.view(-1, 64 * 18 * 18)\n",
    "        x = F.relu(self.batchnorm4(self.fc1(x)))\n",
    "        x = F.dropout(x, 0.2, training=self.training)\n",
    "        x = self.softmax(self.fc2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the model and move it to GPU and add to tensorboard\n",
    "writer = SummaryWriter(\"runs/q1/cnn_dropout\")\n",
    "cnn_model = CNN(block_dropout=False).to(device)\n",
    "writer.add_graph(cnn_model, torch.rand(1, 3, 150, 150).to(device))\n",
    "writer.close()\n",
    "\n",
    "# define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(cnn_model.parameters(), lr=1e-4)\n",
    "\n",
    "# train the model\n",
    "train_loss_cnn, val_loss_cnn, train_acc_cnn, val_acc_cnn = train_model(cnn_model, train_loader, val_loader,\n",
    "                                                                       epochs=10, criterion=criterion, optimizer=optimizer,\n",
    "                                                                       writer=writer, device=device, tensorboard=True, verbose=True)\n",
    "# save the model\n",
    "torch.save(cnn_model.state_dict(), \"cnn_model_droput.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics for the test set\n",
    "\n",
    "print(f'The model has {count_parameters(cnn_model):,} trainable parameters')\n",
    "calculate_metrics(cnn_model, test_loader, classes, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the model and move it to GPU and add to tensorboard\n",
    "writer = SummaryWriter(\"runs/q1/cnn_block_dropout\")\n",
    "cnn_model_dropout = CNN(block_dropout=True).to(device)\n",
    "writer.add_graph(cnn_model_dropout, torch.rand(1, 3, 150, 150).to(device))\n",
    "writer.close()\n",
    "\n",
    "# define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(cnn_model_dropout.parameters(), lr=1e-4)\n",
    "\n",
    "# train the model\n",
    "train_loss_cnn_dropout, val_loss_cnn_dropout, train_acc_cnn_dropout, val_acc_cnn_dropout = train_model(cnn_model_dropout, train_loader, val_loader,\n",
    "                                                                                                       epochs=10, criterion=criterion, optimizer=optimizer, writer=writer,\n",
    "                                                                                                       device=device, tensorboard=True, verbose=True)\n",
    "# save the model\n",
    "torch.save(cnn_model_dropout.state_dict(), \"cnn_model_block_dropout.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics for the test set\n",
    "print(f'The model has {count_parameters(cnn_model_dropout):,} trainable parameters')\n",
    "calculate_metrics(cnn_model_dropout, test_loader, classes, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_factorized(nn.Module):\n",
    "    def __init__(self, block_dropout=True):\n",
    "        super(CNN_factorized, self).__init__()\n",
    "        self.block_dropout = block_dropout\n",
    "        depth_conv1 = nn.Conv2d(3, 3, kernel_size=3, padding=1, groups=3)\n",
    "        point_conv1 = nn.Conv2d(3, 16, kernel_size=1)\n",
    "        depth_conv2 = nn.Conv2d(16, 16, kernel_size=3, padding=1, groups=16)\n",
    "        point_conv2 = nn.Conv2d(16, 32, kernel_size=1)\n",
    "        depth_conv3 = nn.Conv2d(32, 32, kernel_size=3, padding=1, groups=32)\n",
    "        point_conv3 = nn.Conv2d(32, 64, kernel_size=1)\n",
    "        self.depthwise_seperable_conv1 = nn.Sequential(depth_conv1, point_conv1)\n",
    "        self.depthwise_seperable_conv2 = nn.Sequential(depth_conv2, point_conv2)\n",
    "        self.depthwise_seperable_conv3 = nn.Sequential(depth_conv3, point_conv3)\n",
    "        self.fc1 = nn.Linear(64 * 18 * 18, 400)\n",
    "        self.fc2 = nn.Linear(400, 3)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(16)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(32)\n",
    "        self.batchnorm3 = nn.BatchNorm2d(64)\n",
    "        self.batchnorm4 = nn.BatchNorm1d(400)\n",
    "        self.maxpool = nn.MaxPool2d(2, 2)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        if self.block_dropout:\n",
    "            self.dropblock1 = DropBlock2d(0.1, 3)\n",
    "            self.dropblock2 = DropBlock2d(0.1, 3)\n",
    "            self.dropblock3 = DropBlock2d(0.1, 3)\n",
    "    def forward(self, x):\n",
    "        x = self.maxpool(F.relu(self.batchnorm1(self.depthwise_seperable_conv1(x))))\n",
    "        if self.block_dropout:\n",
    "            x = self.dropblock1(x)\n",
    "        else:\n",
    "            x = F.dropout(x, 0.2, training=self.training)\n",
    "        x = self.maxpool(F.relu(self.batchnorm2(self.depthwise_seperable_conv2(x))))\n",
    "        if self.block_dropout:\n",
    "            x = self.dropblock2(x)\n",
    "        else:\n",
    "            x = F.dropout(x, 0.2, training=self.training)\n",
    "        x = self.maxpool(F.relu(self.batchnorm3(self.depthwise_seperable_conv3(x))))\n",
    "        if self.block_dropout:\n",
    "            x = self.dropblock3(x)\n",
    "        else:\n",
    "            x = F.dropout(x, 0.2, training=self.training)\n",
    "        x = x.view(-1, 64 * 18 * 18)\n",
    "        x = F.relu(self.batchnorm4(self.fc1(x)))\n",
    "        x = F.dropout(x, 0.2, training=self.training)\n",
    "        x = self.softmax(self.fc2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the model and move it to GPU and add to tensorboard\n",
    "writer = SummaryWriter(\"runs/q1/cnn_factorized\")\n",
    "cnn_model_factorized = CNN_factorized().to(device)\n",
    "writer.add_graph(cnn_model_factorized, torch.rand(1, 3, 150, 150).to(device))\n",
    "writer.close()\n",
    "\n",
    "# define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(cnn_model_factorized.parameters(), lr=1e-4)\n",
    "\n",
    "# train the model\n",
    "cnn_factorized_train_losses, cnn_factorized_train_acc, cnn_factorized_val_losses, cnn_factorized_val_acc = train_model(cnn_model_factorized, train_loader, val_loader,\n",
    "                                                                                                                       epochs=10, criterion=criterion, optimizer=optimizer, writer=writer,\n",
    "                                                                                                                       device=device, tensorboard=True, verbose=True)\n",
    "# save the model\n",
    "torch.save(cnn_model_factorized.state_dict(), \"cnn_model__factorized.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics for the test set\n",
    "print(f'The model has {count_parameters(cnn_model_factorized):,} trainable parameters')\n",
    "calculate_metrics(cnn_model_factorized, test_loader, classes, device=device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and test losses\n",
    "<span style=\"color:#425066\">⬤</span> FC model\n",
    "<span style=\"color:#12b5cb\">⬤</span> CNN model with simple dropout\n",
    "<span style=\"color:#e52592\">⬤</span> CNN model with block dropout\n",
    "<span style=\"color:#f9ab00\">⬤</span> CNN model with depthwise separable convolution\n",
    "\n",
    "<img src=\"Figures/Loss_train.png\" alt=\"drawing\" height=\"300\"/>\n",
    "<img src=\"Figures/Loss_test.png\" alt=\"drawing\" height=\"300\"/>\n",
    "\n",
    "# Train and test accuracies\n",
    "<span style=\"color:#425066\">⬤</span> FC model\n",
    "<span style=\"color:#12b5cb\">⬤</span> CNN model with simple dropout\n",
    "<span style=\"color:#e52592\">⬤</span> CNN model with block dropout\n",
    "<span style=\"color:#f9ab00\">⬤</span> CNN model with depthwise separable convolution\n",
    "\n",
    "<img src=\"Figures/Accuracy_train.png\" alt=\"drawing\" height=\"300\"/>\n",
    "<img src=\"Figures/Accuracy_test.png\" alt=\"drawing\" height=\"300\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As described in the paper Efficient Object Localization Using Convolutional Networks , if adjacent pixels within feature maps are strongly correlated (as is normally the case in early convolution layers) then i.i.d. dropout will not regularize the activations and will otherwise just result in an effective learning rate decrease."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1cbcb8df23fcabb14b98d08f167303b8612ee566ea031dd4a83c67bd8cdc07a1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
