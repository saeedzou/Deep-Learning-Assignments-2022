{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from utils import calculate_metrics\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\saeedzou/.cache\\torch\\hub\\pytorch_vision_v0.6.0\n",
      "c:\\Users\\saeedzou\\anaconda3\\envs\\torch\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\saeedzou\\anaconda3\\envs\\torch\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# load ResNet50 model\n",
    "model = torch.hub.load('pytorch/vision:v0.6.0', 'resnet50',\n",
    "                          pretrained=True)\n",
    "# change the last layer to 10 classes\n",
    "model.fc = nn.Linear(2048, 10)\n",
    "# freeze all layers except the last layer\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "# move model to GPU\n",
    "model = model.to(device)\n",
    "\n",
    "# load CIFAR-10 dataset\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=torchvision.transforms.ToTensor())\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=torchvision.transforms.ToTensor())\n",
    "# create data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to train the model \n",
    "def train_model(model, train_loader, test_loader, criterion, optimizer, epochs=10):\n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    train_acc = []\n",
    "    test_acc = []\n",
    "    for epoch in range(epochs):\n",
    "        # train\n",
    "        model.train()\n",
    "        train_loss_epoch = 0\n",
    "        train_acc_epoch = 0\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss_epoch += loss.item()\n",
    "            train_acc_epoch += (outputs.argmax(1) == labels).sum().item()\n",
    "        train_loss_epoch /= len(train_loader)\n",
    "        train_acc_epoch /= len(train_loader.dataset)\n",
    "        train_loss.append(train_loss_epoch)\n",
    "        train_acc.append(train_acc_epoch)\n",
    "        # test\n",
    "        model.eval()\n",
    "        test_loss_epoch = 0\n",
    "        test_acc_epoch = 0\n",
    "        with torch.no_grad():\n",
    "            for i, (images, labels) in enumerate(test_loader):\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                test_loss_epoch += loss.item()\n",
    "                test_acc_epoch += (outputs.argmax(1) == labels).sum().item()\n",
    "        test_loss_epoch /= len(test_loader)\n",
    "        test_acc_epoch /= len(test_loader.dataset)\n",
    "        test_loss.append(test_loss_epoch)\n",
    "        test_acc.append(test_acc_epoch)\n",
    "        print(\"Epoch: {}/{} Train Loss: {:.4f} Train Accuracy: {:.4f} Test Loss: {:.4f} Test Accuracy: {:.4f}\".format(epoch+1, epochs, train_loss_epoch, train_acc_epoch, test_loss_epoch, test_acc_epoch))\n",
    "    return train_loss, test_loss, train_acc, test_acc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10 Train Loss: 1.9048 Train Accuracy: 0.3446 Test Loss: 1.6868 Test Accuracy: 0.4388\n",
      "Epoch: 2/10 Train Loss: 1.6564 Train Accuracy: 0.4387 Test Loss: 1.5781 Test Accuracy: 0.4740\n",
      "Epoch: 3/10 Train Loss: 1.5869 Train Accuracy: 0.4621 Test Loss: 1.5444 Test Accuracy: 0.4820\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "train_loss, test_loss, train_acc, test_acc = train_model(model, train_loader, test_loader, criterion, optimizer, epochs=10)\n",
    "\n",
    "# plot the training and test loss and accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_loss, label=\"Train Loss\")\n",
    "plt.plot(test_loss, label=\"Test Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_acc, label=\"Train Accuracy\")\n",
    "plt.plot(test_acc, label=\"Test Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_metrics(model, test_loader, device=device, classes=test_dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load ResNet18 model\n",
    "student_model = torch.hub.load('pytorch/vision:v0.6.0', 'resnet18',\n",
    "                            pretrained=True)\n",
    "# change the last layer to 10 classes\n",
    "student_model.fc = nn.Linear(512, 10)\n",
    "# move model to GPU\n",
    "student_model = student_model.to(device)\n",
    "\n",
    "# define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(student_model.fc.parameters(), lr=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to train the student model\n",
    "def train_student_model(student_model, teacher_model, train_loader, test_loader, criterion, optimizer, epochs=10, T=10, alpha=0.5):\n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    train_acc = []\n",
    "    test_acc = []\n",
    "    for epoch in range(epochs):\n",
    "        # train\n",
    "        student_model.train()\n",
    "        train_loss_epoch = 0\n",
    "        train_acc_epoch = 0\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = student_model(images)\n",
    "            with torch.no_grad():\n",
    "                teacher_outputs = teacher_model(images)\n",
    "            loss = alpha * criterion(outputs, labels) + (1-alpha) * T**2 * criterion(F.log_softmax(outputs/T, dim=1), F.softmax(teacher_outputs/T, dim=1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss_epoch += loss.item()\n",
    "            train_acc_epoch += (outputs.argmax(1) == labels).sum().item()\n",
    "        train_loss_epoch /= len(train_loader)\n",
    "        train_acc_epoch /= len(train_loader.dataset)\n",
    "        train_loss.append(train_loss_epoch)\n",
    "        train_acc.append(train_acc_epoch)\n",
    "        # test\n",
    "        student_model.eval()\n",
    "        test_loss_epoch = 0\n",
    "        test_acc_epoch = 0\n",
    "        with torch.no_grad():\n",
    "            for i, (images, labels) in enumerate(test_loader):\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = student_model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                test_loss_epoch += loss.item()\n",
    "                test_acc_epoch += (outputs.argmax(1) == labels).sum().item()\n",
    "        test_loss_epoch /= len(test_loader)\n",
    "        test_acc_epoch /= len(test_loader.dataset)\n",
    "        test_loss.append(test_loss_epoch)\n",
    "        test_acc.append(test_acc_epoch)\n",
    "        print(\"Epoch: {}/{} Train Loss: {:.4f} Train Accuracy: {:.4f} Test Loss: {:.4f} Test Accuracy: {:.4f}\".format(epoch+1, epochs, train_loss_epoch, train_acc_epoch, test_loss_epoch, test_acc_epoch))\n",
    "    return train_loss, test_loss, train_acc, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'student_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\saeedzou\\Documents\\PycharmProjects\\DeepLearning1401-01\\Assignment 3\\q2.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/saeedzou/Documents/PycharmProjects/DeepLearning1401-01/Assignment%203/q2.ipynb#X13sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m best_acc, best_alpha, best_T\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/saeedzou/Documents/PycharmProjects/DeepLearning1401-01/Assignment%203/q2.ipynb#X13sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m# find the best alpha and T\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/saeedzou/Documents/PycharmProjects/DeepLearning1401-01/Assignment%203/q2.ipynb#X13sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m best_acc, best_alpha, best_T \u001b[39m=\u001b[39m find_best_alpha_T(student_model, model, train_loader, test_loader, criterion, optimizer, epochs\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, T_list\u001b[39m=\u001b[39m[\u001b[39m1\u001b[39m, \u001b[39m10\u001b[39m, \u001b[39m100\u001b[39m], alpha_list\u001b[39m=\u001b[39m[\u001b[39m0.1\u001b[39m, \u001b[39m0.5\u001b[39m, \u001b[39m0.9\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'student_model' is not defined"
     ]
    }
   ],
   "source": [
    "# define a function to find the best alpha and T\n",
    "def find_best_alpha_T(student_model, teacher_model, train_loader, test_loader, criterion, optimizer, epochs=10, T_list=[1, 10, 100], alpha_list=[0.1, 0.5, 0.9]):\n",
    "    best_acc = 0\n",
    "    best_alpha = 0\n",
    "    best_T = 0\n",
    "    for T in T_list:\n",
    "        for alpha in alpha_list:\n",
    "            student_model = torch.hub.load('pytorch/vision:v0.6.0', 'resnet18',\n",
    "                                        pretrained=True)\n",
    "            student_model.fc = nn.Linear(512, 10)\n",
    "            student_model = student_model.to(device)\n",
    "            train_loss, test_loss, train_acc, test_acc = train_student_model(student_model, teacher_model, train_loader, test_loader, criterion, optimizer, epochs=epochs, T=T, alpha=alpha)\n",
    "            if test_acc[-1] > best_acc:\n",
    "                best_acc = test_acc[-1]\n",
    "                best_alpha = alpha\n",
    "                best_T = T\n",
    "    return best_acc, best_alpha, best_T\n",
    "\n",
    "# find the best alpha and T\n",
    "best_acc, best_alpha, best_T = find_best_alpha_T(student_model, model, train_loader, test_loader, criterion, optimizer, epochs=10, T_list=[1, 10, 100], alpha_list=[0.1, 0.5, 0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the student model\n",
    "student_train_loss, student_test_loss, student_train_acc, student_test_acc = train_student_model(student_model, model, train_loader, test_loader, criterion, optimizer, epochs=10, T=10, alpha=0.5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1cbcb8df23fcabb14b98d08f167303b8612ee566ea031dd4a83c67bd8cdc07a1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
