{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from utils import calculate_metrics, train_model, count_parameters\n",
    "import timm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use data augmentation\n",
    "train_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.RandomRotation(10),\n",
    "    torchvision.transforms.ToTensor()\n",
    "])\n",
    "test_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor()\n",
    "])\n",
    "# load CIFAR-10 dataset\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=False, transform=train_transform)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=False, transform=test_transform)\n",
    "# create data loaders\n",
    "train_size = int(0.9 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n",
    "train_dataset.dataset.transform = train_transform\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\saeedzou/.cache\\torch\\hub\\pytorch_vision_v0.6.0\n",
      "c:\\Users\\saeedzou\\anaconda3\\envs\\torch\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\saeedzou\\anaconda3\\envs\\torch\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# load ResNet50 model using timm\n",
    "model = timm.create_model('resnet50', pretrained=True)\n",
    "# change the last layer to 10 classes\n",
    "model.fc = nn.Linear(2048, 10)\n",
    "# freeze all layers except the last layer\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "# move model to GPU\n",
    "model = model.to(device)\n",
    "\n",
    "# define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "print(\"Number of trainable parameters: {}\".format(count_parameters(model)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use train_model function to train the model\n",
    "train_losses, val_losses, train_acc, val_acc = train_model(model, train_loader, val_loader, epochs=10, criterion=criterion, optimizer=optimizer, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # test the model on test data\n",
    "calculate_metrics(model, test_loader, classes=test_dataset.classes, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10 Train Loss: 1.9048 Train Accuracy: 0.3446 Test Loss: 1.6868 Test Accuracy: 0.4388\n",
      "Epoch: 2/10 Train Loss: 1.6564 Train Accuracy: 0.4387 Test Loss: 1.5781 Test Accuracy: 0.4740\n",
      "Epoch: 3/10 Train Loss: 1.5869 Train Accuracy: 0.4621 Test Loss: 1.5444 Test Accuracy: 0.4820\n"
     ]
    }
   ],
   "source": [
    "# plot the training and validation loss and accuracy\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='train')\n",
    "plt.plot(val_losses, label='val')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_acc, label='train')\n",
    "plt.plot(val_acc, label='val')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load ResNet18 model\n",
    "student_model = timm.create_model('resnet18', pretrained=True)\n",
    "# change the last layer to 10 classes\n",
    "student_model.fc = nn.Linear(512, 10)\n",
    "# move model to GPU\n",
    "student_model = student_model.to(device)\n",
    "\n",
    "# define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(student_model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to find the best alpha and T\n",
    "def find_best_alpha_T(student_model, teacher_model, train_loader, test_loader, criterion, optimizer, epochs=10, T_list=[1, 10, 100], alpha_list=[0.1, 0.5, 0.9]):\n",
    "    best_acc = 0\n",
    "    best_alpha = 0\n",
    "    best_T = 0\n",
    "    for T in T_list:\n",
    "        for alpha in alpha_list:\n",
    "            print(f'alpha={alpha}, T={T}')\n",
    "            student_model = timm.create_model('resnet18', pretrained=True)\n",
    "            student_model.fc = nn.Linear(512, 10)\n",
    "            student_model = student_model.to(device)\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            optimizer = optim.Adam(student_model.fc.parameters(), lr=1e-4)\n",
    "            train_loss, test_loss, train_acc, test_acc = train_model(student_model, train_loader, test_loader, epochs=epochs, criterion=criterion, optimizer=optimizer, device=device, teacher_model=model, T=T, alpha=alpha)\n",
    "            if test_acc[-1] > best_acc:\n",
    "                best_acc = test_acc[-1]\n",
    "                best_alpha = alpha\n",
    "                best_T = T\n",
    "    return best_acc, best_alpha, best_T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the best alpha and T\n",
    "best_acc, best_alpha, best_T = find_best_alpha_T(student_model, model, train_loader, val_loader, criterion, optimizer, epochs=4, T_list=[1, 10, 100], alpha_list=[0.1, 0.5, 0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the student model with the best alpha and T\n",
    "student_model = timm.create_model('resnet18', pretrained=True)\n",
    "student_model.fc = nn.Linear(512, 10)\n",
    "student_model = student_model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(student_model.parameters(), lr=1e-4)\n",
    "train_loss, test_loss, train_acc, test_acc = train_model(student_model, train_loader, val_loader, epochs=10, criterion=criterion, optimizer=optimizer, device=device, teacher_model=model, T=best_T, alpha=best_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (pytorch)",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1cbcb8df23fcabb14b98d08f167303b8612ee566ea031dd4a83c67bd8cdc07a1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
