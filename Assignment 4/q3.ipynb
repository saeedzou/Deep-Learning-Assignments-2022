{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saeedzou/DeepLearning1401-01/blob/main/Assignment%204/q3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "fa8_1sCuXu-M"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
        "import gc\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary\n",
        "!pip install -q transformers\n",
        "from transformers import BertTokenizer\n",
        "from transformers import BertModel\n",
        "!pip install -q hazm\n",
        "import hazm\n",
        "import os\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/amnghd/Persian_poems_corpus.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EokojhWYYGuI",
        "outputId": "59d38638-a4a6-4f40-ab12-16254b965cd7"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Persian_poems_corpus'...\n",
            "remote: Enumerating objects: 159, done.\u001b[K\n",
            "remote: Total 159 (delta 0), reused 0 (delta 0), pack-reused 159\u001b[K\n",
            "Receiving objects: 100% (159/159), 45.21 MiB | 16.05 MiB/s, done.\n",
            "Resolving deltas: 100% (3/3), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "poets = ['parvin_norm.txt',\n",
        "         'eraghi_norm.txt',\n",
        "         'bidel_norm.txt',\n",
        "         'gilani_norm.txt',\n",
        "         'helali_norm.txt',\n",
        "         'bahar_norm.txt',\n",
        "         'khosro_norm.txt',\n",
        "         'obeyd_norm.txt',\n",
        "         'vahshi_norm.txt',\n",
        "         'zahir_norm.txt']"
      ],
      "metadata": {
        "id": "OD7vEa-0YLBN"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "for poet in poets:\n",
        "  df = pd.read_csv(os.path.join('Persian_poems_corpus/normalized', poet), header=None, names=['text'])\n",
        "  if len(df) % 2 == 1:\n",
        "    df = df[:-1]\n",
        "  df = pd.DataFrame({'text': [df.iloc[i]['text'] + ' [SEP] ' + df.iloc[i+1]['text'] for i in range(0, len(df), 2)]})\n",
        "  data.append(df)\n",
        "result = pd.concat([df.assign(index=i) for i, df in enumerate(data)], axis=0, ignore_index=True)\n",
        "result = result.sample(frac=1).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "xaZ1LivpfEzL"
      },
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split data into train and val and test\n",
        "trainset = result.iloc[:int(len(result)*0.8)].values\n",
        "valset = result.iloc[int(len(result)*0.8):int(len(result)*0.9)].values\n",
        "testset = result.iloc[int(len(result)*0.9):].values\n",
        "# print the length of each dataset\n",
        "print('train: ', len(trainset))\n",
        "print('val: ', len(valset))\n",
        "print('test: ', len(testset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0evwTiCg4b3",
        "outputId": "069fd7c4-6a6d-4873-e3a5-001c06c23073"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train:  87641\n",
            "val:  10955\n",
            "test:  10956\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res"
      ],
      "metadata": {
        "id": "IOkvUvwFYzSG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "  print(sum(result['index'] == i))"
      ],
      "metadata": {
        "id": "uMAGekkjUMOx",
        "outputId": "764e96e5-2b18-4c78-fefe-d1d0ca8264e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5572\n",
            "5726\n",
            "32332\n",
            "640\n",
            "4288\n",
            "20766\n",
            "23279\n",
            "2807\n",
            "10494\n",
            "3648\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2vwQfo_3Tle7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate max length of poems\n",
        "max_len = 0\n",
        "for poem in trainset:\n",
        "    if len(poem[0].split()) > max_len:\n",
        "        max_len = len(poem[0].split())\n",
        "print('max length of poems: ', max_len)\n",
        "# print the poem with max length\n",
        "print('poem with max length: ', trainset[np.argmax([len(poem[0].split()) for poem in trainset])][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVDrHi0CkUN6",
        "outputId": "7a82fdef-cb20-4844-b0ef-df5b47566b31"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max length of poems:  28\n",
            "poem with max length:  از ما اگر یکی می ماند  شیطان هزار می زاید و اضافه می شود [SEP] در کدام رویا می توانم ببینم  که یک از چنک هزار نجات یابد\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define a dataset class\n",
        "class PoemDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data, tokenizer, max_len):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "        self.texts = [tokenizer(text, padding='max_length', truncation=True, max_length=max_len, return_tensors='pt') for text in self.data[:, 0]]\n",
        "        self.labels = [poet for poet in self.data[:, 1]]\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        return self.texts[index], torch.tensor(self.labels[index]).long()"
      ],
      "metadata": {
        "id": "9yk27Gx7m-WM"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('HooshvareLab/bert-base-parsbert-uncased')\n",
        "train_dataset = PoemDataset(trainset, tokenizer, max_len)\n",
        "val_dataset = PoemDataset(valset, tokenizer, max_len)\n",
        "test_dataset = PoemDataset(testset, tokenizer, max_len)"
      ],
      "metadata": {
        "id": "WUKoIB3-pVYf"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataloaders\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "GfxxEi0jKEct"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ParsBERT = BertModel.from_pretrained('HooshvareLab/bert-fa-base-uncased')\n",
        "# freeze ParsBERT parameters\n",
        "for param in ParsBERT.parameters():\n",
        "    param.requires_grad = False\n",
        "# define a model class\n",
        "class PoemClassifier(nn.Module):\n",
        "    def __init__(self, ParsBERT, num_classes):\n",
        "        super(PoemClassifier, self).__init__()\n",
        "        self.ParsBERT = ParsBERT\n",
        "        self.classifier = nn.Linear(768, num_classes)\n",
        "    \n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        output = self.ParsBERT(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        output = self.classifier(output.pooler_output)\n",
        "        return output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0f_RNpUnznt",
        "outputId": "2aab9ec0-ae6c-4e3f-ff8a-d7ca4a451bae"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at HooshvareLab/bert-fa-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define a function for training\n",
        "def train(model, train_loader, val_loader, optimizer, criterion, epochs, device):\n",
        "    model = model.to(device)\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        train_acc = 0\n",
        "        for i, (inputs, labels) in enumerate(train_loader):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(input_ids=inputs['input_ids'].squeeze(1).to(device), attention_mask=inputs['attention_mask'].to(device))\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "            train_acc += (outputs.argmax(1) == labels).sum().item()\n",
        "        train_loss /= len(train_loader)\n",
        "        train_acc /= len(train_loader.dataset)\n",
        "        val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
        "        print(f'Epoch: {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
        "    return train_loss, train_acc, val_loss, val_acc\n",
        "\n",
        "\n",
        "# define a function for evaluating\n",
        "def evaluate(model, val_loader, criterion, device):\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    val_acc = 0\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(val_loader):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(input_ids=inputs['input_ids'].squeeze(1).to(device), attention_mask=inputs['attention_mask'].to(device))\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "            val_acc += (outputs.argmax(1) == labels).sum().item()\n",
        "    val_loss /= len(val_loader)\n",
        "    val_acc /= len(val_loader.dataset)\n",
        "    return val_loss, val_acc\n",
        "\n"
      ],
      "metadata": {
        "id": "k1KvGktrp_lL"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train the model\n",
        "model = PoemClassifier(ParsBERT, len(poets))\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=5e-5)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "train_loss, train_acc, val_loss, val_acc = train(model, train_loader, val_loader, optimizer, criterion, 5, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDhK6wFMqNTs",
        "outputId": "b3e543fa-128a-46ae-f583-e3174cac6e24"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/5, Train Loss: 1.8693, Train Acc: 0.3835, Val Loss: 1.8256, Val Acc: 0.3864\n",
            "Epoch: 2/5, Train Loss: 1.8239, Train Acc: 0.3863, Val Loss: 1.7951, Val Acc: 0.3895\n",
            "Epoch: 3/5, Train Loss: 1.8053, Train Acc: 0.3885, Val Loss: 1.7799, Val Acc: 0.3931\n",
            "Epoch: 4/5, Train Loss: 1.7942, Train Acc: 0.3905, Val Loss: 1.7661, Val Acc: 0.3954\n",
            "Epoch: 5/5, Train Loss: 1.7850, Train Acc: 0.3929, Val Loss: 1.7602, Val Acc: 0.3952\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save the model\n",
        "torch.save(model.state_dict(), 'poem_classifier.pt')\n",
        "# test the model\n",
        "test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
        "print(f'Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4oDXEmhtEeN",
        "outputId": "31e5da48-805a-4bc2-f46f-ef7241a5fa9d"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 1.7666, Test Acc: 0.3928\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "Ce5ITnUa1n6d"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define a function for predicting\n",
        "def predict(model, poem, tokenizer, max_len, device):\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "    poem = tokenizer(poem, padding='max_length', truncation=True, max_length=max_len, return_tensors='pt')\n",
        "    poem = poem.to(device)\n",
        "    output = model(input_ids=poem['input_ids'].squeeze(1), attention_mask=poem['attention_mask'])\n",
        "    return output.argmax(1).item()\n",
        "\n",
        "# report the results, classification report and confusion matrix\n",
        "y_true = []\n",
        "y_pred = []\n",
        "for i, (inputs, labels) in enumerate(test_loader):\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = model(input_ids=inputs['input_ids'].squeeze(1).to(device), attention_mask=inputs['attention_mask'].to(device))\n",
        "    y_true.extend(labels.tolist())\n",
        "    y_pred.extend(outputs.argmax(1).tolist())\n",
        "print(classification_report(y_true, y_pred, target_names=poets))\n",
        "print(confusion_matrix(y_true, y_pred))\n",
        "print(f1_score(y_true, y_pred, average='macro'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OT8u6P4I0JDW",
        "outputId": "a1095ef7-9d6d-409c-e2f4-3b42ac50222a"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                      precision    recall  f1-score   support\n",
            "\n",
            "     parvin_norm.txt       0.00      0.00      0.00       570\n",
            "   shahriar_norm.txt       0.00      0.00      0.00       185\n",
            "      attar_norm.txt       0.40      0.98      0.57      9517\n",
            "   farrokhi_norm.txt       0.22      0.01      0.02      1212\n",
            "      saadi_norm.txt       0.24      0.01      0.01      1565\n",
            "      bahar_norm.txt       0.28      0.02      0.04      2035\n",
            "       jami_norm.txt       0.35      0.07      0.12      3274\n",
            "     sanaee_norm.txt       0.28      0.01      0.03      2647\n",
            "    moulavi_norm.txt       0.22      0.01      0.01      2612\n",
            "naserkhosro_norm.txt       0.38      0.01      0.01      1128\n",
            "\n",
            "            accuracy                           0.39     24745\n",
            "           macro avg       0.24      0.11      0.08     24745\n",
            "        weighted avg       0.32      0.39      0.24     24745\n",
            "\n",
            "[[   0    0  536    2    0    4   23    2    1    2]\n",
            " [   0    0  166    2    4    2    6    2    3    0]\n",
            " [   0    0 9362    5    2    9  117    7   12    3]\n",
            " [   0    0 1124   12    2   20   20   30    3    1]\n",
            " [   0    0 1478    7   12    9   44    9    5    1]\n",
            " [   0    0 1863   12    7   38   92   12    8    3]\n",
            " [   0    0 3015    1    1    6  236    8    7    0]\n",
            " [   0    0 2491   11    6   23   64   35   16    1]\n",
            " [   0    0 2518    1    9   13   40   13   16    2]\n",
            " [   0    0 1068    2    6   12   24    6    2    8]]\n",
            "0.08047520717923345\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-tuning with SGD and Adam"
      ],
      "metadata": {
        "id": "B8ouIoMa1zE6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define another model where ParsBERT is not frozen\n",
        "ParsBERT = BertModel.from_pretrained('HooshvareLab/bert-fa-base-uncased')\n",
        "model = PoemClassifier(ParsBERT, len(poets))\n",
        "# train the model once with SGD optimizer and once with Adam optimizer\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# we want to measure perplexity before and after training. select 1000 unbiased samples from the test set\n",
        "# Get unique labels\n",
        "labels = np.unique(test[:, 1])\n",
        "# Initialize empty list to store samples\n",
        "samples = []\n",
        "# Loop over unique labels\n",
        "for label in labels:\n",
        "    # Get indices of samples with the current label\n",
        "    indices = np.where(test[:, 1] == label)[0]\n",
        "    # Randomly select 100 samples from those indices and get the corresponding samples\n",
        "    samples.append(test[np.random.choice(indices, 100, replace=False)])\n",
        "# Concatenate all samples into a single numpy array\n",
        "samples_dataset = PoemDataset(np.concatenate(samples))\n",
        "# Create a dataloader for the samples\n",
        "samples_loader = DataLoader(samples_dataset, batch_size=32, shuffle=True)\n",
        "# test the model\n",
        "test_loss, test_acc = evaluate(model, samples_loader, criterion, device)\n",
        "# calculate perplexity\n",
        "perplexity = np.exp(test_loss)\n",
        "print(f'Perplexity before training: {perplexity:.4f}')\n",
        "# train the model once with SGD optimizer\n",
        "train_loss, train_acc, val_loss, val_acc = train(model, train_loader, val_loader, optimizer, criterion, 10, device)\n",
        "# save the model\n",
        "torch.save(model.state_dict(), 'poem_classifier_sgd.pt')\n",
        "# test the model\n",
        "test_loss, test_acc = evaluate(model, samples_loader, criterion, device)\n",
        "# calculate perplexity\n",
        "perplexity = np.exp(test_loss)\n",
        "print(f'Perplexity after training: {perplexity:.4f}')\n",
        "print(f'Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}')\n",
        "# report the results, classification report and confusion matrix\n",
        "y_true = []\n",
        "y_pred = []\n",
        "for i, (inputs, labels) in enumerate(test_loader):\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = model(input_ids=inputs['input_ids'].squeeze(1).to(device), attention_mask=inputs['attention_mask'].to(device))\n",
        "    y_true.extend(labels.tolist())\n",
        "    y_pred.extend(outputs.argmax(1).tolist())\n",
        "print(classification_report(y_true, y_pred, target_names=poets))\n",
        "print(confusion_matrix(y_true, y_pred))"
      ],
      "metadata": {
        "id": "l91L6Q1W1yZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define another model where ParsBERT is not frozen\n",
        "ParsBERT = BertModel.from_pretrained('HooshvareLab/bert-fa-base-uncased')\n",
        "model = PoemClassifier(ParsBERT, len(poets))\n",
        "# train the model once with SGD optimizer and once with Adam optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# we want to measure perplexity before and after training. select 1000 unbiased samples from the test set\n",
        "# test the model\n",
        "test_loss, test_acc = evaluate(model, samples_loader, criterion, device)\n",
        "# calculate perplexity\n",
        "perplexity = np.exp(test_loss)\n",
        "print(f'Perplexity before training: {perplexity:.4f}')\n",
        "# train the model once with Adam optimizer\n",
        "train_loss, train_acc, val_loss, val_acc = train(model, train_loader, val_loader, optimizer, criterion, 10, device)\n",
        "# save the model\n",
        "torch.save(model.state_dict(), 'poem_classifier_adam.pt')\n",
        "# test the model\n",
        "test_loss, test_acc = evaluate(model, samples_loader, criterion, device)\n",
        "# calculate perplexity\n",
        "perplexity = np.exp(test_loss)\n",
        "print(f'Perplexity after training: {perplexity:.4f}')\n",
        "print(f'Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}')\n",
        "# report the results, classification report and confusion matrix\n",
        "y_true = []\n",
        "y_pred = []\n",
        "for i, (inputs, labels) in enumerate(test_loader):\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = model(input_ids=inputs['input_ids'].squeeze(1).to(device), attention_mask=inputs['attention_mask'].to(device))\n",
        "    y_true.extend(labels.tolist())\n",
        "    y_pred.extend(outputs.argmax(1).tolist())\n",
        "print(classification_report(y_true, y_pred, target_names=poets))\n",
        "print(confusion_matrix(y_true, y_pred))"
      ],
      "metadata": {
        "id": "97ZxnKhu12lb"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}