{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43XEpWwu9ZQH",
        "outputId": "b8e3ac92-5c85-4b55-ab90-b1d1b292c734"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# import necessary libraries for pytorch to train a sequence-to-sequence model using LSTM cells to generate poems of Ferdousi\n",
        "# the dataset is in ferdousi.txt which is in persian\n",
        "# the model is trained on a GPU\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import sent_tokenize\n",
        "# # for persian\n",
        "# !pip install hazm -q\n",
        "# from hazm import *\n",
        "import string\n",
        "from collections import Counter\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxNjFSQr9dmh",
        "outputId": "98c34048-7b48-4361-9964-28efa4e415c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'Persian_poems_corpus'...\n",
            "remote: Enumerating objects: 159, done.\u001b[K\n",
            "remote: Total 159 (delta 0), reused 0 (delta 0), pack-reused 159\u001b[K\n",
            "Receiving objects: 100% (159/159), 45.21 MiB | 17.15 MiB/s, done.\n",
            "Resolving deltas: 100% (3/3), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/amnghd/Persian_poems_corpus.git\n",
        "!cp Persian_poems_corpus/original/ferdousi.txt .\n",
        "!rm -rf Persian_poems_corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8OFdtzP_IgSO"
      },
      "outputs": [],
      "source": [
        "class FerdousiDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, poem_path):\n",
        "        self.poem_path = poem_path\n",
        "        self.load_poem()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.poem)-1\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.poem[idx], self.poem[idx+1]\n",
        "\n",
        "    def load_poem(self):\n",
        "        with open(self.poem_path, 'r', encoding='utf-8') as f:\n",
        "            poem = [line.strip() for line in f.readlines()]\n",
        "        poem = poem[2:]\n",
        "        poem = poem[:-1] if len(poem) % 2 == 1 else poem\n",
        "        poem = [[poem[i], poem[i+1]] for i in range(0, len(poem), 2)]\n",
        "        poem = [mesra[0] + ' ' + mesra[1] for mesra in poem]\n",
        "        poem = [word_tokenize(line) for line in poem]\n",
        "        punctuations = string.punctuation + '«»،؛؟'\n",
        "        poem = [[word for word in line if word not in punctuations] for line in poem]\n",
        "        poem = [[word for word in line if not word.isdigit()] for line in poem]\n",
        "        poem = [line for line in poem if len(line) > 0]\n",
        "        poem = [[word for word in line if len(word) > 1] for line in poem]\n",
        "        self.max_len = max([len(line) for line in poem])\n",
        "        poem = [line + ['<pad>'] * (self.max_len - len(line)) for line in poem]\n",
        "        poem = [['<sos>'] + line + ['<eos>'] for line in poem]\n",
        "        words = Counter([word for line in poem for word in line])\n",
        "        self.word2idx = {word: idx for idx, word in enumerate(words)}\n",
        "        self.idx2word = {idx: word for idx, word in enumerate(words)}\n",
        "        poem = [[self.word2idx[word] for word in line] for line in poem]\n",
        "        self.poem = torch.tensor(poem).long()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "d9tLaOUoIiSi"
      },
      "outputs": [],
      "source": [
        "# create a dataset object\n",
        "dataset = FerdousiDataset('ferdousi.txt')\n",
        "# split the dataset into train and test\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
        "# create a dataloader for train and test\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "GCemRPIzIjq2"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size, embedding_size, hidden_size, num_layers):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "        self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, batch_first=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x.shape = (batch_size, seq_len)\n",
        "        embedding = self.embedding(x)\n",
        "        # embedding.shape = (batch_size, seq_len, embedding_size)\n",
        "        outputs, (hidden, cell) = self.rnn(embedding)\n",
        "        # outputs.shape = (batch_size, seq_len, hidden_size)\n",
        "        # hidden.shape = (num_layers, batch_size, hidden_size)\n",
        "        # cell.shape = (num_layers, batch_size, hidden_size)\n",
        "        return hidden, cell\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, input_size, embedding_size, hidden_size, num_layers):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "        self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, input_size)\n",
        "\n",
        "    def forward(self, x, hidden, cell):\n",
        "        # x.shape = (batch_size, seq_len)\n",
        "        embedding = self.embedding(x)\n",
        "        # embedding.shape = (batch_size, seq_len, embedding_size)\n",
        "        outputs, (hidden, cell) = self.rnn(embedding, (hidden, cell))\n",
        "        # outputs.shape = (batch_size, seq_len, hidden_size)\n",
        "        # hidden.shape = (num_layers, batch_size, hidden_size)\n",
        "        # cell.shape = (num_layers, batch_size, hidden_size)\n",
        "        predictions = self.fc(outputs)\n",
        "        # predictions.shape = (batch_size, seq_len, input_size)\n",
        "        return predictions, hidden, cell\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "AqW0PiIEImoQ"
      },
      "outputs": [],
      "source": [
        "# define a function to train the model and return the loss of the model on the train and test set\n",
        "def train(encoder, decoder, train_loader, test_loader, encoder_optimizer, decoder_optimizer, criterion, num_epochs):\n",
        "    train_losses = []\n",
        "    test_losses = []\n",
        "    for epoch in range(num_epochs):\n",
        "        encoder.train()\n",
        "        decoder.train()\n",
        "        train_loss = 0\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            data = data[:, :-1].to(device)\n",
        "            target = target[:, 1:].to(device)\n",
        "            encoder_optimizer.zero_grad()\n",
        "            decoder_optimizer.zero_grad()\n",
        "            hidden, cell = encoder(data)\n",
        "            predictions, _, _ = decoder(target, hidden, cell)\n",
        "            loss = criterion(predictions.reshape(-1, predictions.shape[-1]), target.reshape(-1))\n",
        "            loss.backward()\n",
        "            encoder_optimizer.step()\n",
        "            decoder_optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "        train_loss /= len(train_loader)\n",
        "        train_losses.append(train_loss)\n",
        "        encoder.eval()\n",
        "        decoder.eval()\n",
        "        test_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, (data, target) in enumerate(test_loader):\n",
        "                data = data[:, :-1].to(device)\n",
        "                target = target[:, 1:].to(device)\n",
        "                hidden, cell = encoder(data)\n",
        "                predictions, _, _ = decoder(target, hidden, cell)\n",
        "                loss = criterion(predictions.reshape(-1, predictions.shape[-1]), target.reshape(-1))\n",
        "                test_loss += loss.item()\n",
        "        test_loss /= len(test_loader)\n",
        "        test_losses.append(test_loss)\n",
        "        print('Epoch: {}/{}, Train Loss: {:.4f}, Test Loss: {:.4f}'.format(epoch+1, num_epochs, train_loss, test_loss))\n",
        "    return train_losses, test_losses\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "63d_XLpGIlIm"
      },
      "outputs": [],
      "source": [
        "# create an encoder and decoder object\n",
        "encoder = Encoder(len(dataset.word2idx), 256, 512, 3)\n",
        "decoder = Decoder(len(dataset.word2idx), 256, 512, 3)\n",
        "encoder = encoder.to(device)\n",
        "decoder = decoder.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sf6cQC_lKwVI",
        "outputId": "647fd375-f741-491a-9c8d-6d1716f47cf4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1/4, Train Loss: 2.0578, Test Loss: 0.7773\n",
            "Epoch: 2/4, Train Loss: 0.4609, Test Loss: 0.3548\n",
            "Epoch: 3/4, Train Loss: 0.1785, Test Loss: 0.2513\n",
            "Epoch: 4/4, Train Loss: 0.0762, Test Loss: 0.2191\n"
          ]
        }
      ],
      "source": [
        "# define the optimizer and criterion\n",
        "encoder_optimizer = torch.optim.Adam(encoder.parameters(), lr=0.001)\n",
        "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# train the model\n",
        "train_losses, test_losses = train(encoder, decoder, train_loader, test_loader, encoder_optimizer, decoder_optimizer, criterion, 4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "osQofss2Np3-",
        "outputId": "37a67fb3-e7e1-4ded-e400-6508574fcc5b"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(train_losses, label='train')\n",
        "plt.plot(test_losses, label='test')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "hogycTJ4L0hY"
      },
      "outputs": [],
      "source": [
        "# create a function called convert_to_text to convert a list of indices to a string without the <pad>, <sos>, and <eos> tokens\n",
        "def convert_to_text(indices):\n",
        "    text = ''\n",
        "    for index in indices:\n",
        "        if index == dataset.word2idx['<pad>'] or index == dataset.word2idx['<sos>'] or index == dataset.word2idx['<eos>']:\n",
        "            continue\n",
        "        text += dataset.idx2word[index] + ' '\n",
        "    return text\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "9_vEVms1MmXe"
      },
      "outputs": [],
      "source": [
        "# define a function to generate a given number of verses given a random verse from the dataset\n",
        "def generate(encoder, decoder, num_verses):\n",
        "    encoder.eval()\n",
        "    decoder.eval()\n",
        "    with torch.no_grad():\n",
        "        verse = dataset[random.randint(0, len(dataset)-1)][0]\n",
        "        print(convert_to_text(verse.numpy()))\n",
        "        verse = verse.unsqueeze(0).to(device)\n",
        "        hidden, cell = encoder(verse)\n",
        "        generated_verses = []\n",
        "        for i in range(num_verses):\n",
        "            generated_verse = []\n",
        "            x = torch.tensor([[dataset.word2idx['<sos>']]]).to(device)\n",
        "            for j in range(verse.shape[1]):\n",
        "                predictions, hidden, cell = decoder(x, hidden, cell)\n",
        "                predicted_index = torch.argmax(predictions, dim=2)\n",
        "                generated_verse.append(predicted_index.item())\n",
        "                x = predicted_index\n",
        "            generated_verses.append(convert_to_text(generated_verse))\n",
        "    return generated_verses\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z63Fi3sfMoRq",
        "outputId": "92d1709d-b441-40bb-93b1-778c88f2dd2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "برآمد هر سوی دز رستخیز ندیدند جایی گذار گریز \n",
            "Generated Verses:\n",
            "زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ \n",
            "زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ \n",
            "زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ \n",
            "زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ \n",
            "زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ \n",
            "زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ \n",
            "زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ \n",
            "زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ \n",
            "زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ \n",
            "زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ زرسپ \n"
          ]
        }
      ],
      "source": [
        "generated_verses = generate(encoder, decoder, 10)\n",
        "print('Generated Verses:')\n",
        "for verse in generated_verses:\n",
        "    print(verse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "_rTpMFGrM1wu"
      },
      "outputs": [],
      "source": [
        "# define new encoder and decoder classes like before but with Bidirectional GRU\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size, embedding_size, hidden_size, num_layers):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "        self.rnn = nn.GRU(embedding_size, hidden_size, num_layers, bidirectional=True)\n",
        "        self.fc = nn.Linear(hidden_size*2, hidden_size)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # x.shape = (batch_size, seq_len)\n",
        "        embedding = self.embedding(x)\n",
        "        # embedding.shape = (batch_size, seq_len, embedding_size)\n",
        "        outputs, hidden = self.rnn(embedding)\n",
        "        # outputs.shape = (batch_size, seq_len, hidden_size*2)\n",
        "        # hidden.shape = (num_layers*2, batch_size, hidden_size)\n",
        "        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)))\n",
        "        # hidden.shape = (batch_size, hidden_size)\n",
        "        return hidden\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "        self.rnn = nn.GRU(embedding_size, hidden_size, num_layers)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "        \n",
        "    def forward(self, x, hidden):\n",
        "        # x.shape = (batch_size, 1)\n",
        "        # hidden.shape = (num_layers, batch_size, hidden_size)\n",
        "        x = x.unsqueeze(0)\n",
        "        # x.shape = (1, batch_size, 1)\n",
        "        embedding = self.embedding(x)\n",
        "        # embedding.shape = (1, batch_size, embedding_size)\n",
        "        output, hidden = self.rnn(embedding, hidden)\n",
        "        # output.shape = (1, batch_size, hidden_size)\n",
        "        # hidden.shape = (num_layers, batch_size, hidden_size)\n",
        "        predictions = self.fc(output)\n",
        "        # predictions.shape = (1, batch_size, output_size)\n",
        "        predictions = predictions.squeeze(0)\n",
        "        # predictions.shape = (batch_size, output_size)\n",
        "        return predictions, hidden\n",
        "\n",
        "# define the encoder and decoder\n",
        "encoder = Encoder(len(dataset.word2idx), 100, 256, 2).to(device)\n",
        "decoder = Decoder(len(dataset.word2idx), 100, 256, len(dataset.word2idx), 2).to(device)\n",
        "\n",
        "# define the optimizer and criterion\n",
        "encoder_optimizer = torch.optim.Adam(encoder.parameters(), lr=0.001)\n",
        "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.0 (tags/v3.9.0:9cf6752, Oct  5 2020, 15:34:40) [MSC v.1927 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "4fbe9694f7587329a2893969593bb646d9caf203732995a36644052b7dd475e8"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
