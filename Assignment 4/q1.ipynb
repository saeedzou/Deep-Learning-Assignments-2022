{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saeedzou/DeepLearning1401-01/blob/main/Assignment%204/q1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43XEpWwu9ZQH",
        "outputId": "30005a23-a3a1-4afe-8c44-4a8c8d29232a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# import necessary libraries for pytorch to train a sequence-to-sequence model using LSTM cells to generate poems of Ferdousi\n",
        "# the dataset is in ferdousi.txt which is in persian\n",
        "# the model is trained on a GPU\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import sent_tokenize\n",
        "# # for persian\n",
        "# !pip install hazm -q\n",
        "# from hazm import *\n",
        "import string\n",
        "from collections import Counter\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxNjFSQr9dmh",
        "outputId": "e0a80c64-e359-4bf8-9cbd-0698da3435f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Persian_poems_corpus'...\n",
            "remote: Enumerating objects: 159, done.\u001b[K\n",
            "remote: Total 159 (delta 0), reused 0 (delta 0), pack-reused 159\u001b[K\n",
            "Receiving objects: 100% (159/159), 45.21 MiB | 12.82 MiB/s, done.\n",
            "Resolving deltas: 100% (3/3), done.\n",
            "Updating files: 100% (148/148), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/amnghd/Persian_poems_corpus.git\n",
        "!cp Persian_poems_corpus/original/ferdousi.txt .\n",
        "!rm -rf Persian_poems_corpus"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Vocabulary:\n",
        "    def __init__(self, poem_path, threshold):\n",
        "        self.poem_path = poem_path\n",
        "        self.threshold = threshold\n",
        "        self.load_poem()\n",
        "        self.build_vocab()\n",
        "        \n",
        "    def load_poem(self):\n",
        "        with open(self.poem_path, 'r', encoding='utf-8') as f:\n",
        "            poem = [line.strip() for line in f.readlines()]\n",
        "        poem = poem[2:]\n",
        "        poem = poem[:-1] if len(poem) % 2 == 1 else poem\n",
        "        poem = [[poem[i], poem[i+1]] for i in range(0, len(poem), 2)]\n",
        "        poem = [mesra[0] + ' <sep> ' + mesra[1] for mesra in poem]\n",
        "        punctuations = string.punctuation + '«»،؛؟'\n",
        "        self.lines = [[word.lower() for word in line.split() if word not in punctuations] for line in poem]\n",
        "    \n",
        "    def build_vocab(self):\n",
        "        words = [word for line in self.lines for word in line]\n",
        "        word_counts = Counter(words)\n",
        "        words = [word for word, count in word_counts.items() if count >= self.threshold]\n",
        "        self.word2idx = {word: idx for idx, word in enumerate(words)}\n",
        "        self.word2idx['<pad>'] = len(self.word2idx)\n",
        "        self.word2idx['<sos>'] = len(self.word2idx)\n",
        "        self.word2idx['<eos>'] = len(self.word2idx)\n",
        "        self.word2idx['<unk>'] = len(self.word2idx)\n",
        "        self.word2idx['<sep>'] = len(self.word2idx)\n",
        "        self.idx2word = {idx: word for word, idx in self.word2idx.items()}"
      ],
      "metadata": {
        "id": "4N95HrKECC81"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "8OFdtzP_IgSO"
      },
      "outputs": [],
      "source": [
        "class FerdousiDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, poem_path, vocab):\n",
        "        self.poem_path = poem_path\n",
        "        self.vocab = vocab\n",
        "        self.load_poem()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.poem) - 1\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.poem[idx], self.poem[idx + 1]\n",
        "\n",
        "    def load_poem(self):\n",
        "        with open(self.poem_path, 'r', encoding='utf-8') as f:\n",
        "            poem = [line.strip() for line in f.readlines()]\n",
        "        poem = poem[2:]\n",
        "        poem = poem[:-1] if len(poem) % 2 == 1 else poem\n",
        "        poem = [[poem[i], poem[i + 1]] for i in range(0, len(poem), 2)]\n",
        "        poem = [mesra[0] + ' <sep> ' + mesra[1] for mesra in poem]\n",
        "        poem = [word_tokenize(line) for line in poem]\n",
        "        punctuations = string.punctuation + '«»،؛؟'\n",
        "        poem = [[word for word in line if word not in punctuations] for line in poem]\n",
        "        poem = [line for line in poem if len(line) > 0]\n",
        "        poem = [[word for word in line if len(word) > 1] for line in poem]\n",
        "        self.max_len = max([len(line) for line in poem])\n",
        "        poem = [line + ['<pad>'] * (self.max_len - len(line)) for line in poem]\n",
        "        poem = [['<sos>'] + line + ['<eos>'] for line in poem]\n",
        "\n",
        "        # Create word vectors using the vocabulary\n",
        "        self.poem = []\n",
        "        for line in poem:\n",
        "            line_vec = []\n",
        "            for word in line:\n",
        "                if word in self.vocab.word2idx:\n",
        "                    line_vec.append(self.vocab.word2idx[word])\n",
        "                else:\n",
        "                    line_vec.append(self.vocab.word2idx['<unk>'])\n",
        "            self.poem.append(line_vec)\n",
        "        self.poem = torch.tensor(self.poem).long()\n",
        "\n",
        "vocab = Vocabulary('ferdousi.txt', 2)\n",
        "# create a dataset object\n",
        "dataset = FerdousiDataset('ferdousi.txt', vocab)\n",
        "# split the dataset into train and test\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
        "# create a dataloader for train and test\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "iZv8z6vBmB8r"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size, embedding_size, hidden_size, num_layers, p_drop=0.1):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "        self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.dropout = nn.Dropout(p_drop)\n",
        "\n",
        "    def forward(self, x, hidden=None, cell=None):\n",
        "        # x.shape = (batch_size, seq_len)\n",
        "        embedding = self.dropout(self.embedding(x))\n",
        "        # embedding.shape = (batch_size, seq_len, embedding_size)\n",
        "        if hidden is None and cell is None:\n",
        "            hidden = torch.zeros((self.num_layers, x.shape[0], self.hidden_size), device=x.device)\n",
        "            cell = torch.zeros((self.num_layers, x.shape[0], self.hidden_size), device=x.device)\n",
        "        outputs, (hidden, cell) = self.rnn(embedding, (hidden, cell))\n",
        "        # outputs.shape = (batch_size, seq_len, hidden_size)\n",
        "        # hidden.shape = (num_layers, batch_size, hidden_size)\n",
        "        # cell.shape = (num_layers, batch_size, hidden_size)\n",
        "        return hidden, cell\n",
        "\n",
        "# define the decoder class and use the encoder.embedding as the embedding layer\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers, p_drop=0.1):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.embedding = encoder.embedding\n",
        "        self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "        self.dropout = nn.Dropout(p_drop)\n",
        "\n",
        "    def forward(self, x, hidden, cell):\n",
        "        # x.shape = (batch_size, 1)\n",
        "        x = x.unsqueeze(1)\n",
        "        # x.shape = (batch_size, 1, 1)\n",
        "        embedding = self.dropout(self.embedding(x))\n",
        "        # embedding.shape = (batch_size, 1, embedding_size)\n",
        "        outputs, (hidden, cell) = self.rnn(embedding, (hidden, cell))\n",
        "        # outputs.shape = (batch_size, 1, hidden_size)\n",
        "        # hidden.shape = (num_layers, batch_size, hidden_size)\n",
        "        # cell.shape = (num_layers, batch_size, hidden_size)\n",
        "        predictions = self.fc(outputs)\n",
        "        # predictions.shape = (batch_size, 1, output_size)\n",
        "        predictions = predictions.squeeze(1)\n",
        "        # predictions.shape = (batch_size, output_size)\n",
        "        return predictions, hidden, cell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "GCemRPIzIjq2"
      },
      "outputs": [],
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, source, target, teacher_forcing_ratio=0.8):\n",
        "        # source.shape = (batch_size, source_seq_len)\n",
        "        # target.shape = (batch_size, target_seq_len)\n",
        "        batch_size = source.shape[0]\n",
        "        target_len = target.shape[1]\n",
        "        target_vocab_size = len(dataset.vocab.word2idx)\n",
        "        outputs = torch.zeros(batch_size, target_len, target_vocab_size).to(device)\n",
        "        hidden, cell = self.encoder(source)\n",
        "        # hidden.shape = (num_layers, batch_size, hidden_size)\n",
        "        # cell.shape = (num_layers, batch_size, hidden_size)\n",
        "        x = target[:, 0]\n",
        "        # x.shape = (batch_size)\n",
        "        for t in range(1, target_len):\n",
        "            output, hidden, cell = self.decoder(x, hidden, cell)\n",
        "            # output.shape = (batch_size, target_vocab_size)\n",
        "            outputs[:, t] = output\n",
        "            best_guess = output.argmax(1)\n",
        "            x = target[:, t] if random.random() < teacher_forcing_ratio else best_guess\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "OOV95ro2mB8v"
      },
      "outputs": [],
      "source": [
        "# encoder hyperparameters\n",
        "input_size_encoder = len(dataset.vocab.word2idx)\n",
        "encoder_embedding_size = 200\n",
        "hidden_size = 128\n",
        "num_layers = 2\n",
        "# define the encoder\n",
        "encoder = Encoder(input_size_encoder, encoder_embedding_size, hidden_size, num_layers).to(device)\n",
        "# decoder hyperparameters\n",
        "input_size_decoder = len(dataset.vocab.word2idx)\n",
        "output_size = len(dataset.vocab.word2idx)\n",
        "decoder_embedding_size = 200\n",
        "hidden_size = 128\n",
        "num_layers = 2\n",
        "# define the decoder\n",
        "decoder = Decoder(input_size_decoder, decoder_embedding_size, hidden_size, output_size, num_layers).to(device)\n",
        "num_epochs = 50\n",
        "learning_rate = 1e-3\n",
        "# initialize the network\n",
        "encoder_net = Encoder(input_size_encoder, encoder_embedding_size, hidden_size, num_layers).to(device)\n",
        "decoder_net = Decoder(input_size_decoder, decoder_embedding_size, hidden_size, output_size, num_layers).to(device)\n",
        "model = Seq2Seq(encoder_net, decoder_net).to(device)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=dataset.vocab.word2idx['<pad>'])\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "n9bR1WYkmB8w"
      },
      "outputs": [],
      "source": [
        "# define a function that takes a tensor of indices and returns a string and removes pad and end and start tokens\n",
        "def tensor2string(tensor):\n",
        "    # tensor.shape = (seq_len)\n",
        "    words = [dataset.vocab.idx2word[idx.item()] for idx in tensor]\n",
        "    words = [word for word in words if word not in ['<pad>', '<sos>', '<eos>']]\n",
        "    return ' '.join(words)\n",
        "\n",
        "# define a function that generates a verse\n",
        "def generate_verse(model, source, device, max_len=20):\n",
        "    source = source.unsqueeze(0)\n",
        "    model.eval()\n",
        "    # dont forget to move to device\n",
        "    with torch.no_grad():\n",
        "        hidden, cell = model.encoder(source.to(device))\n",
        "        # hidden.shape = (num_layers, batch_size, hidden_size)\n",
        "        # cell.shape = (num_layers, batch_size, hidden_size)\n",
        "        x = torch.tensor([dataset.vocab.word2idx['<sos>']]).to(device)\n",
        "        outputs = []\n",
        "        for t in range(max_len):\n",
        "            output, hidden, cell = model.decoder(x, hidden, cell)\n",
        "            # output.shape = (1, output_size)\n",
        "            best_guess = output.argmax(1)\n",
        "            outputs.append(best_guess.item())\n",
        "            x = best_guess\n",
        "            if best_guess.item() == dataset.vocab.word2idx['<eos>']:\n",
        "                break\n",
        "    return tensor2string(torch.tensor(outputs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "HLN3HUVBmB8x"
      },
      "outputs": [],
      "source": [
        "# define a function that trains the model\n",
        "def train(model, train_loader, val_loader, criterion, optimizer, num_epochs, device):\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    train_accuracies = []\n",
        "    val_accuracies = []\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loss = 0\n",
        "        train_accuracy = 0\n",
        "        idx = random.randint(0, len(train_dataset))\n",
        "        verse = train_dataset[idx][0].to(device)\n",
        "        print(generate_verse(model, verse, device=device))\n",
        "        model.train()\n",
        "        for (source, target) in train_loader:\n",
        "            source = source.to(device)\n",
        "            target = target.to(device)\n",
        "            outputs = model(source, target)\n",
        "            # outputs.shape = (batch_size, target_seq_len, output_size)\n",
        "            outputs = outputs[:, 1:].reshape(-1, outputs.shape[2])\n",
        "            # outputs.shape = (batch_size * target_seq_len, output_size)\n",
        "            target = target[:, 1:].reshape(-1)\n",
        "            # target.shape = (batch_size * target_seq_len)\n",
        "            loss = criterion(outputs, target)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "            top_p, top_class = outputs.topk(1, dim=1)\n",
        "            # top_p.shape = (batch_size * target_seq_len, 1)\n",
        "            # top_class.shape = (batch_size * target_seq_len, 1)\n",
        "            equals = top_class == target.view(*top_class.shape)\n",
        "            # equals.shape = (batch_size * target_seq_len, 1)\n",
        "            train_accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
        "        train_losses.append(train_loss / len(train_loader))\n",
        "        train_accuracies.append(train_accuracy / len(train_loader))\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        val_accuracy = 0\n",
        "        with torch.no_grad():\n",
        "            for (source, target) in val_loader:\n",
        "                source = source.to(device)\n",
        "                target = target.to(device)\n",
        "                outputs = model(source, target)\n",
        "                # outputs.shape = (batch_size, target_seq_len, output_size)\n",
        "                outputs = outputs[:, 1:].reshape(-1, outputs.shape[2])\n",
        "                # outputs.shape = (batch_size * target_seq_len, output_size)\n",
        "                target = target[:, 1:].reshape(-1)\n",
        "                # target.shape = (batch_size * target_seq_len)\n",
        "                loss = criterion(outputs, target)\n",
        "                val_loss += loss.item()\n",
        "                top_p, top_class = outputs.topk(1, dim=1)\n",
        "                # top_p.shape = (batch_size * target_seq_len, 1)\n",
        "                # top_class.shape = (batch_size * target_seq_len, 1)\n",
        "                equals = top_class == target.view(*top_class.shape)\n",
        "                # equals.shape = (batch_size * target_seq_len, 1)\n",
        "                val_accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
        "        val_losses.append(val_loss / len(val_loader))\n",
        "        val_accuracies.append(val_accuracy / len(val_loader))\n",
        "        print(f'Epoch {epoch + 1}/{num_epochs} | Train Loss: {train_losses[-1]:.4f} | Train Accuracy: {train_accuracies[-1]:.4f} | Val Loss: {val_losses[-1]:.4f} | Val Accuracy: {val_accuracies[-1]:.4f}')\n",
        "    return train_losses, val_losses, train_accuracies, val_accuracies"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses, val_losses, train_accuracies, val_accuracies = train(model, train_loader, test_loader, criterion, optimizer, num_epochs, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPx2Q4M6ICR0",
        "outputId": "7bedc6b1-ee38-4fb0-b8d4-084f628c084e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "خواهم شارهٔ شارهٔ شارهٔ بیندت ساله بیندت ساله کارآن چندشان زگرد بکه نشناختند شهد بکه شهد شهد کهترانند انگاه بلاغت\n",
            "Epoch 1/50 | Train Loss: 5.9615 | Train Accuracy: 0.1232 | Val Loss: 5.7065 | Val Accuracy: 0.1305\n",
            "به از که از بر <unk> <unk> <unk> به بر بر بر به راه اوی\n",
            "Epoch 2/50 | Train Loss: 5.5735 | Train Accuracy: 0.1358 | Val Loss: 5.5037 | Val Accuracy: 0.1399\n",
            "چو گفت با شاه <unk> <unk> <unk> <unk> از بر <unk> بر <unk> به دست اوی اوی\n",
            "Epoch 3/50 | Train Loss: 5.3755 | Train Accuracy: 0.1431 | Val Loss: 5.3624 | Val Accuracy: 0.1455\n",
            "چو گفت که ای <unk> <unk> <unk> <unk> <unk> <unk> <unk> به راه به راه اوی اوی\n",
            "Epoch 4/50 | Train Loss: 5.2138 | Train Accuracy: 0.1493 | Val Loss: 5.2461 | Val Accuracy: 0.1511\n",
            "چو بشنید شد از <unk> <unk> <unk> <unk> از از بر او را به پای بود\n",
            "Epoch 5/50 | Train Loss: 5.0755 | Train Accuracy: 0.1547 | Val Loss: 5.1433 | Val Accuracy: 0.1557\n",
            "چو گفت با او <unk> <unk> <unk> که از <unk> <unk> به دست به دست به دست بود\n",
            "Epoch 6/50 | Train Loss: 4.9671 | Train Accuracy: 0.1590 | Val Loss: 5.0972 | Val Accuracy: 0.1584\n",
            "چو از بر تخت زرین ستام <unk> به پیش اندرون بر سر کلاه کلاه کلاه کلاه کلاه\n",
            "Epoch 7/50 | Train Loss: 4.8840 | Train Accuracy: 0.1622 | Val Loss: 5.0486 | Val Accuracy: 0.1616\n",
            "چو گفت با شاه <unk> <unk> <unk> که از <unk> از کارزار تفت به راه راه\n",
            "Epoch 8/50 | Train Loss: 4.7918 | Train Accuracy: 0.1661 | Val Loss: 4.9925 | Val Accuracy: 0.1647\n",
            "چو از بر تخت زرین ستام <unk> به بر سر بر سر نهاد پای پای خاست\n",
            "Epoch 9/50 | Train Loss: 4.7336 | Train Accuracy: 0.1689 | Val Loss: 4.9869 | Val Accuracy: 0.1656\n",
            "چو از بر تخت زرین نهاد <unk> به بر سر بر نهاد از میان گروه خاست\n",
            "Epoch 10/50 | Train Loss: 4.6654 | Train Accuracy: 0.1722 | Val Loss: 4.9791 | Val Accuracy: 0.1673\n",
            "چو از بر شاه ایران رسید <unk> که از را دید با کرنای جفت جفت\n",
            "Epoch 11/50 | Train Loss: 4.6045 | Train Accuracy: 0.1745 | Val Loss: 4.9491 | Val Accuracy: 0.1686\n",
            "چو شد از لشکر پیلتن <unk> که از شد به کردار شیر ژیان را ندید\n",
            "Epoch 12/50 | Train Loss: 4.5538 | Train Accuracy: 0.1773 | Val Loss: 4.9546 | Val Accuracy: 0.1702\n",
            "چو گفت با او <unk> <unk> <unk> که از <unk> از <unk> <unk> نیست راست گوی نیست\n",
            "Epoch 13/50 | Train Loss: 4.5115 | Train Accuracy: 0.1797 | Val Loss: 4.9176 | Val Accuracy: 0.1722\n",
            "چو از به نزدیک شاه <unk> <unk> به نزدیک شاه آمد از بارگاه سپاه راه سپاه راه سپاه\n",
            "Epoch 14/50 | Train Loss: 4.4699 | Train Accuracy: 0.1818 | Val Loss: 4.9112 | Val Accuracy: 0.1740\n",
            "چو گفت کای شاه ایران <unk> <unk> <unk> به <unk> به جای نشست به پای بود\n",
            "Epoch 15/50 | Train Loss: 4.4315 | Train Accuracy: 0.1834 | Val Loss: 4.9678 | Val Accuracy: 0.1718\n",
            "چو بشنید که این کار <unk> <unk> <unk> به از تو <unk> <unk> نیست نیست\n",
            "Epoch 16/50 | Train Loss: 4.3888 | Train Accuracy: 0.1861 | Val Loss: 4.8986 | Val Accuracy: 0.1770\n",
            "که از تو به <unk> <unk> <unk> <unk> <unk> <unk> به <unk> <unk> به جنگ افگنی <unk>\n",
            "Epoch 17/50 | Train Loss: 4.3620 | Train Accuracy: 0.1873 | Val Loss: 4.9076 | Val Accuracy: 0.1769\n",
            "که که از تو <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> نیست نیست نیست\n",
            "Epoch 18/50 | Train Loss: 4.3046 | Train Accuracy: 0.1908 | Val Loss: 4.9333 | Val Accuracy: 0.1764\n",
            "چو از به نزدیک شاه <unk> <unk> <unk> به نزدیک شاه سپاه راه راه سپاه راه گناه\n",
            "Epoch 19/50 | Train Loss: 4.2864 | Train Accuracy: 0.1917 | Val Loss: 4.9507 | Val Accuracy: 0.1765\n",
            "همان نیز با او <unk> <unk> <unk> به هر سو که بد به دست به دست\n",
            "Epoch 20/50 | Train Loss: 4.2338 | Train Accuracy: 0.1948 | Val Loss: 4.9361 | Val Accuracy: 0.1780\n",
            "همه <unk> کرد <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> کرد چاک چاک چاک چاک چاک\n",
            "Epoch 21/50 | Train Loss: 4.2206 | Train Accuracy: 0.1959 | Val Loss: 4.9552 | Val Accuracy: 0.1779\n",
            "چو بشنید آن نامه را <unk> <unk> <unk> به از بر شاه <unk> بخواند به پای خاست\n",
            "Epoch 22/50 | Train Loss: 4.1858 | Train Accuracy: 0.1977 | Val Loss: 4.9658 | Val Accuracy: 0.1779\n",
            "چو آمد به نزدیک افراسیاب <unk> که از شد از کوه دشت آفتاب آفتاب\n",
            "Epoch 23/50 | Train Loss: 4.1583 | Train Accuracy: 0.1997 | Val Loss: 4.9562 | Val Accuracy: 0.1793\n",
            "<unk> <unk> را <unk> <unk> <unk> <unk> <unk> به <unk> بر <unk> بر سبوی پاک خواست نیست\n",
            "Epoch 24/50 | Train Loss: 4.1158 | Train Accuracy: 0.2017 | Val Loss: 4.9876 | Val Accuracy: 0.1772\n",
            "بدو گفت کای شاه ایران <unk> <unk> که از <unk> از تو <unk> کیست ای نامجوی\n",
            "Epoch 25/50 | Train Loss: 4.0952 | Train Accuracy: 0.2039 | Val Loss: 4.9959 | Val Accuracy: 0.1788\n",
            "چو از دور شد به <unk> <unk> <unk> همی کرد بر مهرهٔ پشت راست کرد از نخست\n",
            "Epoch 26/50 | Train Loss: 4.0696 | Train Accuracy: 0.2051 | Val Loss: 5.0280 | Val Accuracy: 0.1778\n",
            "همه موبدان آفرین خواندند <unk> زبرجد برافشاندند آفرین خواندند آفرین خواندند آفرین افشاندند را بخوان\n",
            "Epoch 27/50 | Train Loss: 4.0659 | Train Accuracy: 0.2059 | Val Loss: 5.0101 | Val Accuracy: 0.1787\n",
            "همه مهتران را بخواند <unk> <unk> به نزدیک شاه بنهاد تفت براند راه نشاند پیش\n",
            "Epoch 28/50 | Train Loss: 4.0282 | Train Accuracy: 0.2080 | Val Loss: 5.0067 | Val Accuracy: 0.1793\n",
            "که من با تو از <unk> <unk> <unk> به <unk> بر تو <unk> زمین\n",
            "Epoch 29/50 | Train Loss: 4.0201 | Train Accuracy: 0.2087 | Val Loss: 4.9969 | Val Accuracy: 0.1804\n",
            "چو از دور شد به <unk> <unk> <unk> به کردار آتش برآمد خروش خروس چاک چاک ودشت\n",
            "Epoch 30/50 | Train Loss: 3.9831 | Train Accuracy: 0.2113 | Val Loss: 5.0217 | Val Accuracy: 0.1800\n",
            "بفرمود تا پیش او شد دبیر <unk> به نزدیک موبد پیر دبیر پذیر دبیر پذیر\n",
            "Epoch 31/50 | Train Loss: 3.9726 | Train Accuracy: 0.2117 | Val Loss: 5.0612 | Val Accuracy: 0.1793\n",
            "به <unk> سپردند <unk> <unk> به <unk> بر شاه <unk> رهنمای پای فخر فخر\n",
            "Epoch 32/50 | Train Loss: 3.9388 | Train Accuracy: 0.2140 | Val Loss: 5.0501 | Val Accuracy: 0.1805\n",
            "به گفت که ای شاه را <unk> <unk> <unk> را به داد آفرین کرد کرد\n",
            "Epoch 33/50 | Train Loss: 3.9298 | Train Accuracy: 0.2153 | Val Loss: 5.0713 | Val Accuracy: 0.1795\n",
            "چو بشنید گفتار او را <unk> <unk> به نزدیک او را به دست بست خاست راست\n",
            "Epoch 34/50 | Train Loss: 3.9019 | Train Accuracy: 0.2166 | Val Loss: 5.0999 | Val Accuracy: 0.1781\n",
            "یکی نیزه زد بر کمربند اوی <unk> همه تیره شد روی اوی اوی اوی اوی اوی\n",
            "Epoch 35/50 | Train Loss: 3.8826 | Train Accuracy: 0.2181 | Val Loss: 5.0780 | Val Accuracy: 0.1805\n",
            "وزان جایگه شد سوی طیسفون <unk> به هر جای ویرانی از رهنمون رهنمون نه\n",
            "Epoch 36/50 | Train Loss: 3.8721 | Train Accuracy: 0.2194 | Val Loss: 5.1582 | Val Accuracy: 0.1766\n",
            "اگر من که از تو <unk> <unk> <unk> به <unk> بر تو بر تو کیست جفت توجست\n",
            "Epoch 37/50 | Train Loss: 3.8570 | Train Accuracy: 0.2198 | Val Loss: 5.1367 | Val Accuracy: 0.1790\n",
            "چو بشنید رستم که شد <unk> <unk> <unk> به از بر شد از خاک خاک شد تیره خاک\n",
            "Epoch 38/50 | Train Loss: 3.8483 | Train Accuracy: 0.2206 | Val Loss: 5.1762 | Val Accuracy: 0.1771\n",
            "اگر شاه را من به <unk> <unk> <unk> که <unk> <unk> بر تو آید به جنگ آیمت\n",
            "Epoch 39/50 | Train Loss: 3.8150 | Train Accuracy: 0.2233 | Val Loss: 5.1466 | Val Accuracy: 0.1791\n",
            "به پیش شهنشاه برخاستند <unk> به مژگان همی خون برخ برفشاند زدند از میان برزدند آمدند\n",
            "Epoch 40/50 | Train Loss: 3.8046 | Train Accuracy: 0.2240 | Val Loss: 5.2022 | Val Accuracy: 0.1772\n",
            "برآمد خروشیدن گاودم <unk> زمین شد بکردار دریای خون خون آژده ناب گلاب\n",
            "Epoch 41/50 | Train Loss: 3.7600 | Train Accuracy: 0.2271 | Val Loss: 5.1764 | Val Accuracy: 0.1785\n",
            "گر از من همی بازجویی سخن <unk> که از تو <unk> کهن کهن داشتم بن بن بن بن بن بن\n",
            "Epoch 42/50 | Train Loss: 3.7553 | Train Accuracy: 0.2269 | Val Loss: 5.2105 | Val Accuracy: 0.1781\n",
            "بدو گفت کای شاه با من بگوی <unk> که از این بد به روی روی روی\n",
            "Epoch 43/50 | Train Loss: 3.7480 | Train Accuracy: 0.2281 | Val Loss: 5.2102 | Val Accuracy: 0.1776\n",
            "وگر هیچ تاب اندر آید به <unk> <unk> به <unk> بر تو آید به جنگ رستخیز مغاک اندرند\n",
            "Epoch 44/50 | Train Loss: 3.7456 | Train Accuracy: 0.2285 | Val Loss: 5.2329 | Val Accuracy: 0.1773\n",
            "به ایران بفرمود تا شهریار <unk> به نزدیک آن نامدار انجمن نامدار دبیر هزار هزار\n",
            "Epoch 45/50 | Train Loss: 3.7241 | Train Accuracy: 0.2297 | Val Loss: 5.2392 | Val Accuracy: 0.1768\n",
            "که این را را به <unk> <unk> <unk> <unk> به <unk> به به جنگ اندرند آمدن\n",
            "Epoch 46/50 | Train Loss: 3.7228 | Train Accuracy: 0.2304 | Val Loss: 5.2294 | Val Accuracy: 0.1784\n",
            "به گیتی مرا شارستانست ای <unk> به <unk> به به دانش به شیرین بدی آرزوی آرزوی ست\n",
            "Epoch 47/50 | Train Loss: 3.6774 | Train Accuracy: 0.2332 | Val Loss: 5.2810 | Val Accuracy: 0.1765\n",
            "وگر من را تو <unk> <unk> <unk> <unk> که <unk> <unk> <unk> <unk> <unk> نیست روی پرند\n",
            "Epoch 48/50 | Train Loss: 3.6587 | Train Accuracy: 0.2349 | Val Loss: 5.3001 | Val Accuracy: 0.1751\n",
            "بتازند گردان بدین رزمگاه <unk> <unk> که از بر مور بر پشه راه راه سپاه راه\n",
            "Epoch 49/50 | Train Loss: 3.6646 | Train Accuracy: 0.2347 | Val Loss: 5.2767 | Val Accuracy: 0.1782\n",
            "که من پیش من بر <unk> <unk> <unk> به از تو آرم به دل بامنند دست\n",
            "Epoch 50/50 | Train Loss: 3.6582 | Train Accuracy: 0.2352 | Val Loss: 5.2860 | Val Accuracy: 0.1776\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(train_losses, label='train losses')\n",
        "plt.plot(val_losses, label='val losses')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.plot(train_accuracies, label='train accs')\n",
        "plt.plot(val_accuracies, label='val accs')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 516
        },
        "id": "JAlvLPELXHKt",
        "outputId": "61c02d02-aedc-4b01-d273-35cd5678364b"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To generate verses I only select those generated verses that have unique words in them and their length is more than 12"
      ],
      "metadata": {
        "id": "N8Du_GENXDVi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define a function that takes a tensor of indices and returns a string and removes pad and end and start tokens\n",
        "def tensor2string(tensor):\n",
        "    # tensor.shape = (seq_len)\n",
        "    words = [dataset.vocab.idx2word[idx.item()] for idx in tensor]\n",
        "    words = [word for word in words if word not in ['<pad>', '<sos>', '<eos>', '<unk>']]\n",
        "    return ' '.join(words)\n",
        "print(\"Some Generated Verses: \")\n",
        "i = 0\n",
        "while not i == 10:\n",
        "  idx = random.randint(0, len(train_dataset))\n",
        "  verse = train_dataset[idx][0].to(device)\n",
        "  generated = generate_verse(model, verse, device=device)\n",
        "  if len(generated.split()) > 12:\n",
        "    counts = Counter(generated.split())\n",
        "    counts = sorted(counts.items(), key=lambda x: x[1], reverse=True)\n",
        "    if counts[0][1] == 1:\n",
        "      i += 1\n",
        "      print(generated)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBflKC3bUmK2",
        "outputId": "0d2ced37-ad2a-459e-94c2-d322a303ebaf"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Some Generated Verses: \n",
            "کنون چون نشستیم با او که بر ما ربودی همی پشت گام پرند\n",
            "چو از دور دیدند بر همی رفت با او به جای نو گام زن\n",
            "سیاوش بدو گفت کای شهریار که من نیاید به کار زار سیر آر تاو\n",
            "چنین گفت با شاه ایران که ای نامداران گردان من سخن در گمان یادگار بگیر را بخوان\n",
            "چو از پیش او شد به بر آن بگشاد لب را بکشت جفت\n",
            "پس آگاهی آمد به ایران سپاه که از خونشان شد آوردگاه سیاه آمدند\n",
            "یکی نیزه انداخت بر گردنش به ابر اندر آورده روی زمین برزدند زدند\n",
            "بگویم ترا هرچ گفتی بطوس به از تیرگیها بیفروزدش رنگ بوی مست جوی چنگ\n",
            "بدو گفت بهرام کای شهریار که من نیاید به کار زار سیر آر خار خو\n",
            "چو من بگذرم زین سپنجی سرای که تو را باشدت رهنمای خدای نشست دست پای\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "9ytn4TkOnYiU"
      },
      "outputs": [],
      "source": [
        "# define another encoder with Bidirectional GRU\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size, embedding_size, hidden_size, num_layers, p_drop=0.1):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "        self.gru = nn.GRU(embedding_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
        "        self.dropout = nn.Dropout(p_drop)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x.shape = (batch_size, seq_len)\n",
        "        embedding = self.dropout(self.embedding(x))\n",
        "        # embedding.shape = (batch_size, seq_len, embedding_size)\n",
        "        outputs, hidden = self.gru(embedding)\n",
        "        # outputs.shape = (batch_size, seq_len, hidden_size * 2)\n",
        "        # hidden.shape = (num_layers * 2, batch_size, hidden_size)\n",
        "        return hidden\n",
        "\n",
        "# define decoder with bidirectional GRU\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers, p_drop=0.1):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.embedding = encoder.embedding\n",
        "        self.rnn = nn.GRU(embedding_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
        "        self.fc = nn.Linear(hidden_size * 2, output_size)  # since bidirectional, so multiply by 2\n",
        "        self.dropout = nn.Dropout(p_drop)\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        # x.shape = (batch_size, 1)\n",
        "        x = x.unsqueeze(1)\n",
        "        # x.shape = (batch_size, 1, 1)\n",
        "        embedding = self.dropout(self.embedding(x))\n",
        "        # embedding.shape = (batch_size, 1, embedding_size)\n",
        "        outputs, hidden = self.rnn(embedding, hidden)\n",
        "        # outputs.shape = (batch_size, 1, hidden_size * 2)  # since bidirectional, so hidden_size * 2\n",
        "        # hidden.shape = (num_layers * 2, batch_size, hidden_size)  # since bidirectional, so num_layers * 2\n",
        "        predictions = self.fc(outputs)\n",
        "        # predictions.shape = (batch_size, 1, output_size)\n",
        "        predictions = predictions.squeeze(1)\n",
        "        # predictions.shape = (batch_size, output_size)\n",
        "        return predictions, hidden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "9zzrUjLI-SiG"
      },
      "outputs": [],
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, source, target, teacher_forcing_ratio=0.5):\n",
        "        # source.shape = (batch_size, source_seq_len)\n",
        "        # target.shape = (batch_size, target_seq_len)\n",
        "        batch_size = source.shape[0]\n",
        "        target_len = target.shape[1]\n",
        "        target_vocab_size = len(dataset.vocab.word2idx)\n",
        "        outputs = torch.zeros(batch_size, target_len, target_vocab_size).to(device)\n",
        "        hidden = self.encoder(source)\n",
        "        # hidden.shape = (batch_size, 2*hidden_size)\n",
        "        x = target[:, 0]\n",
        "        # x.shape = (batch_size)\n",
        "        for t in range(1, target_len):\n",
        "            output, hidden = self.decoder(x, hidden)\n",
        "            # output.shape = (batch_size, target_vocab_size)\n",
        "            outputs[:, t] = output\n",
        "            best_guess = output.argmax(1)\n",
        "            x = target[:, t] if random.random() < teacher_forcing_ratio else best_guess\n",
        "        return outputs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "-SVMBPKm-SiH"
      },
      "outputs": [],
      "source": [
        "# hyperparameters\n",
        "input_size_encoder = len(dataset.vocab.word2idx)\n",
        "encoder_embedding_size = 200\n",
        "hidden_size = 128\n",
        "num_layers = 2\n",
        "# define the encoder\n",
        "encoder = Encoder(input_size_encoder, encoder_embedding_size, hidden_size, num_layers).to(device)\n",
        "# hyperparameters\n",
        "input_size_decoder = len(dataset.vocab.word2idx)\n",
        "output_size = len(dataset.vocab.word2idx)\n",
        "decoder_embedding_size = 200\n",
        "hidden_size = 128\n",
        "num_layers = 2\n",
        "num_epochs = 25\n",
        "# define the decoder\n",
        "decoder = Decoder(input_size_decoder, decoder_embedding_size, hidden_size, output_size, num_layers).to(device)\n",
        "model = Seq2Seq(encoder, decoder).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=dataset.vocab.word2idx['<pad>'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define a function that takes a tensor of indices and returns a string and removes pad and end and start tokens\n",
        "def tensor2string(tensor):\n",
        "    # tensor.shape = (seq_len)\n",
        "    words = [dataset.vocab.idx2word[idx.item()] for idx in tensor]\n",
        "    words = [word for word in words if word not in ['<pad>', '<sos>', '<eos>']]\n",
        "    return ' '.join(words)\n",
        "\n",
        "# define a function that generates a verse\n",
        "def generate_verse_gru(model, source, device, max_len=20):\n",
        "    source = source.unsqueeze(0)\n",
        "    model.eval()\n",
        "    # dont forget to move to device\n",
        "    with torch.no_grad():\n",
        "        hidden = model.encoder(source.to(device))\n",
        "        # hidden.shape = (num_layers, batch_size, hidden_size)\n",
        "        # cell.shape = (num_layers, batch_size, hidden_size)\n",
        "        x = torch.tensor([dataset.vocab.word2idx['<sos>']]).to(device)\n",
        "        outputs = []\n",
        "        for t in range(max_len):\n",
        "            output, hidden = model.decoder(x, hidden)\n",
        "            # output.shape = (1, output_size)\n",
        "            best_guess = output.argmax(1)\n",
        "            outputs.append(best_guess.item())\n",
        "            x = best_guess\n",
        "            if best_guess.item() == dataset.vocab.word2idx['<eos>']:\n",
        "                break\n",
        "    return tensor2string(torch.tensor(outputs))"
      ],
      "metadata": {
        "id": "NofHrnyya_Q2"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "EucbtXK1-SiH"
      },
      "outputs": [],
      "source": [
        "# define a function that trains the model\n",
        "def train(model, train_loader, val_loader, criterion, optimizer, num_epochs, device, generate_verse):\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    train_accuracies = []\n",
        "    val_accuracies = []\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loss = 0\n",
        "        train_accuracy = 0\n",
        "        idx = random.randint(0, len(train_dataset))\n",
        "        verse = train_dataset[idx][0].to(device)\n",
        "        print(generate_verse(model, verse, device=device))\n",
        "        model.train()\n",
        "        for (source, target) in train_loader:\n",
        "            source = source.to(device)\n",
        "            target = target.to(device)\n",
        "            outputs = model(source, target)\n",
        "            # outputs.shape = (batch_size, target_seq_len, output_size)\n",
        "            outputs = outputs[:, 1:].reshape(-1, outputs.shape[2])\n",
        "            # outputs.shape = (batch_size * target_seq_len, output_size)\n",
        "            target = target[:, 1:].reshape(-1)\n",
        "            # target.shape = (batch_size * target_seq_len)\n",
        "            loss = criterion(outputs, target)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "            top_p, top_class = outputs.topk(1, dim=1)\n",
        "            # top_p.shape = (batch_size * target_seq_len, 1)\n",
        "            # top_class.shape = (batch_size * target_seq_len, 1)\n",
        "            equals = top_class == target.view(*top_class.shape)\n",
        "            # equals.shape = (batch_size * target_seq_len, 1)\n",
        "            train_accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
        "        train_losses.append(train_loss / len(train_loader))\n",
        "        train_accuracies.append(train_accuracy / len(train_loader))\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        val_accuracy = 0\n",
        "        with torch.no_grad():\n",
        "            for (source, target) in val_loader:\n",
        "                source = source.to(device)\n",
        "                target = target.to(device)\n",
        "                outputs = model(source, target)\n",
        "                # outputs.shape = (batch_size, target_seq_len, output_size)\n",
        "                outputs = outputs[:, 1:].reshape(-1, outputs.shape[2])\n",
        "                # outputs.shape = (batch_size * target_seq_len, output_size)\n",
        "                target = target[:, 1:].reshape(-1)\n",
        "                # target.shape = (batch_size * target_seq_len)\n",
        "                loss = criterion(outputs, target)\n",
        "                val_loss += loss.item()\n",
        "                top_p, top_class = outputs.topk(1, dim=1)\n",
        "                # top_p.shape = (batch_size * target_seq_len, 1)\n",
        "                # top_class.shape = (batch_size * target_seq_len, 1)\n",
        "                equals = top_class == target.view(*top_class.shape)\n",
        "                # equals.shape = (batch_size * target_seq_len, 1)\n",
        "                val_accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
        "        val_losses.append(val_loss / len(val_loader))\n",
        "        val_accuracies.append(val_accuracy / len(val_loader))\n",
        "        print(f'Epoch {epoch + 1}/{num_epochs} | Train Loss: {train_losses[-1]:.4f} | Train Accuracy: {train_accuracies[-1]:.4f} | Val Loss: {val_losses[-1]:.4f} | Val Accuracy: {val_accuracies[-1]:.4f}')\n",
        "    return train_losses, val_losses, train_accuracies, val_accuracies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SnjsZFJk-SiI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d3a12b2-7a82-4cf9-8a23-b0c4f55b8bac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "فرهنگیان گرسیوزست زکار میش تنگست سرافگنده سرافگنده سخنهای افروزش افروزش کشیدندش کشیدندش پیمانت رستمت رخساره محمد کشیدندش رخساره کمست بسازند\n"
          ]
        }
      ],
      "source": [
        "train_losses, val_losses, train_accuracies, val_accuracies = train(model, train_loader, test_loader, criterion, optimizer, num_epochs, device, generate_verse_gru)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define a function that takes a tensor of indices and returns a string and removes pad and end and start tokens\n",
        "def tensor2string(tensor):\n",
        "    # tensor.shape = (seq_len)\n",
        "    words = [dataset.vocab.idx2word[idx.item()] for idx in tensor]\n",
        "    words = [word for word in words if word not in ['<pad>', '<sos>', '<eos>', '<unk>']]\n",
        "    return ' '.join(words)\n",
        "print(\"Some Generated Verses: \")\n",
        "i = 0\n",
        "while not i == 10:\n",
        "  idx = random.randint(0, len(train_dataset))\n",
        "  verse = train_dataset[idx][0].to(device)\n",
        "  generated = generate_verse_gru(model, verse, device=device)\n",
        "  if len(generated.split()) > 12:\n",
        "    counts = Counter(generated.split())\n",
        "    counts = sorted(counts.items(), key=lambda x: x[1], reverse=True)\n",
        "    if counts[0][1] == 1:\n",
        "      i += 1\n",
        "      print(generated)"
      ],
      "metadata": {
        "id": "ETTeBnj-bpyx"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0 (tags/v3.9.0:9cf6752, Oct  5 2020, 15:34:40) [MSC v.1927 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "4fbe9694f7587329a2893969593bb646d9caf203732995a36644052b7dd475e8"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}