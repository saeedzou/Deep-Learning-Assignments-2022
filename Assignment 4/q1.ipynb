{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saeedzou/DeepLearning1401-01/blob/main/Assignment%204/q1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43XEpWwu9ZQH",
        "outputId": "d62ac808-085d-422e-c4fa-4e8d5cfeda9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "# import necessary libraries for pytorch to train a sequence-to-sequence model using LSTM cells to generate poems of Ferdousi\n",
        "# the dataset is in ferdousi.txt which is in persian\n",
        "# the model is trained on a GPU\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import sent_tokenize\n",
        "# # for persian\n",
        "# !pip install hazm -q\n",
        "# from hazm import *\n",
        "import string\n",
        "from collections import Counter\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxNjFSQr9dmh",
        "outputId": "b9709c23-eea2-48d5-dcd6-a4418f584dba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Persian_poems_corpus'...\n",
            "remote: Enumerating objects: 159, done.\u001b[K\n",
            "remote: Total 159 (delta 0), reused 0 (delta 0), pack-reused 159\u001b[K\n",
            "Receiving objects: 100% (159/159), 45.21 MiB | 11.20 MiB/s, done.\n",
            "Resolving deltas: 100% (3/3), done.\n",
            "Updating files: 100% (148/148), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/amnghd/Persian_poems_corpus.git\n",
        "!cp Persian_poems_corpus/original/ferdousi.txt .\n",
        "!rm -rf Persian_poems_corpus"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Vocabulary:\n",
        "    def __init__(self, poem_path, threshold):\n",
        "        self.poem_path = poem_path\n",
        "        self.threshold = threshold\n",
        "        self.load_poem()\n",
        "        self.build_vocab()\n",
        "        \n",
        "    def load_poem(self):\n",
        "        with open(self.poem_path, 'r', encoding='utf-8') as f:\n",
        "            poem = [line.strip() for line in f.readlines()]\n",
        "        poem = poem[2:]\n",
        "        poem = poem[:-1] if len(poem) % 2 == 1 else poem\n",
        "        poem = [[poem[i], poem[i+1]] for i in range(0, len(poem), 2)]\n",
        "        poem = [mesra[0] + ' <sep> ' + mesra[1] for mesra in poem]\n",
        "        punctuations = string.punctuation + '«»،؛؟'\n",
        "        self.lines = [[word.lower() for word in line.split() if word not in punctuations] for line in poem]\n",
        "    \n",
        "    def build_vocab(self):\n",
        "        words = [word for line in self.lines for word in line]\n",
        "        word_counts = Counter(words)\n",
        "        words = [word for word, count in word_counts.items() if count >= self.threshold]\n",
        "        self.word2idx = {word: idx for idx, word in enumerate(words)}\n",
        "        self.word2idx['<pad>'] = len(self.word2idx)\n",
        "        self.word2idx['<sos>'] = len(self.word2idx)\n",
        "        self.word2idx['<eos>'] = len(self.word2idx)\n",
        "        self.word2idx['<unk>'] = len(self.word2idx)\n",
        "        self.word2idx['<sep>'] = len(self.word2idx)\n",
        "        self.idx2word = {idx: word for word, idx in self.word2idx.items()}"
      ],
      "metadata": {
        "id": "4N95HrKECC81"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8OFdtzP_IgSO"
      },
      "outputs": [],
      "source": [
        "class FerdousiDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, poem_path, vocab):\n",
        "        self.poem_path = poem_path\n",
        "        self.vocab = vocab\n",
        "        self.load_poem()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.poem) - 1\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.poem[idx], self.poem[idx + 1]\n",
        "\n",
        "    def load_poem(self):\n",
        "        with open(self.poem_path, 'r', encoding='utf-8') as f:\n",
        "            poem = [line.strip() for line in f.readlines()]\n",
        "        poem = poem[2:]\n",
        "        poem = poem[:-1] if len(poem) % 2 == 1 else poem\n",
        "        poem = [[poem[i], poem[i + 1]] for i in range(0, len(poem), 2)]\n",
        "        poem = [mesra[0] + ' <sep> ' + mesra[1] for mesra in poem]\n",
        "        poem = [word_tokenize(line) for line in poem]\n",
        "        punctuations = string.punctuation + '«»،؛؟'\n",
        "        poem = [[word for word in line if word not in punctuations] for line in poem]\n",
        "        poem = [line for line in poem if len(line) > 0]\n",
        "        poem = [[word for word in line if len(word) > 1] for line in poem]\n",
        "        self.max_len = max([len(line) for line in poem])\n",
        "        poem = [line + ['<pad>'] * (self.max_len - len(line)) for line in poem]\n",
        "        poem = [['<sos>'] + line + ['<eos>'] for line in poem]\n",
        "\n",
        "        # Create word vectors using the vocabulary\n",
        "        self.poem = []\n",
        "        for line in poem:\n",
        "            line_vec = []\n",
        "            for word in line:\n",
        "                if word in self.vocab.word2idx:\n",
        "                    line_vec.append(self.vocab.word2idx[word])\n",
        "                else:\n",
        "                    line_vec.append(self.vocab.word2idx['<unk>'])\n",
        "            self.poem.append(line_vec)\n",
        "        self.poem = torch.tensor(self.poem).long()\n",
        "\n",
        "vocab = Vocabulary('ferdousi.txt', 2)\n",
        "# create a dataset object\n",
        "dataset = FerdousiDataset('ferdousi.txt', vocab)\n",
        "# split the dataset into train and test\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
        "# create a dataloader for train and test\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "iZv8z6vBmB8r"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size, embedding_size, hidden_size, num_layers, p_drop=0.1):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "        self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.dropout = nn.Dropout(p_drop)\n",
        "\n",
        "    def forward(self, x, hidden=None, cell=None):\n",
        "        # x.shape = (batch_size, seq_len)\n",
        "        embedding = self.dropout(self.embedding(x))\n",
        "        # embedding.shape = (batch_size, seq_len, embedding_size)\n",
        "        if hidden is None and cell is None:\n",
        "            hidden = torch.zeros((self.num_layers, x.shape[0], self.hidden_size), device=x.device)\n",
        "            cell = torch.zeros((self.num_layers, x.shape[0], self.hidden_size), device=x.device)\n",
        "        outputs, (hidden, cell) = self.rnn(embedding, (hidden, cell))\n",
        "        # outputs.shape = (batch_size, seq_len, hidden_size)\n",
        "        # hidden.shape = (num_layers, batch_size, hidden_size)\n",
        "        # cell.shape = (num_layers, batch_size, hidden_size)\n",
        "        return hidden, cell\n",
        "\n",
        "# define the decoder class and use the encoder.embedding as the embedding layer\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers, p_drop=0.1):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.embedding = encoder.embedding\n",
        "        self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "        self.dropout = nn.Dropout(p_drop)\n",
        "\n",
        "    def forward(self, x, hidden, cell):\n",
        "        # x.shape = (batch_size, 1)\n",
        "        x = x.unsqueeze(1)\n",
        "        # x.shape = (batch_size, 1, 1)\n",
        "        embedding = self.dropout(self.embedding(x))\n",
        "        # embedding.shape = (batch_size, 1, embedding_size)\n",
        "        outputs, (hidden, cell) = self.rnn(embedding, (hidden, cell))\n",
        "        # outputs.shape = (batch_size, 1, hidden_size)\n",
        "        # hidden.shape = (num_layers, batch_size, hidden_size)\n",
        "        # cell.shape = (num_layers, batch_size, hidden_size)\n",
        "        predictions = self.fc(outputs)\n",
        "        # predictions.shape = (batch_size, 1, output_size)\n",
        "        predictions = predictions.squeeze(1)\n",
        "        # predictions.shape = (batch_size, output_size)\n",
        "        return predictions, hidden, cell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "GCemRPIzIjq2"
      },
      "outputs": [],
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, source, target, teacher_forcing_ratio=0.8):\n",
        "        # source.shape = (batch_size, source_seq_len)\n",
        "        # target.shape = (batch_size, target_seq_len)\n",
        "        batch_size = source.shape[0]\n",
        "        target_len = target.shape[1]\n",
        "        target_vocab_size = len(dataset.vocab.word2idx)\n",
        "        outputs = torch.zeros(batch_size, target_len, target_vocab_size).to(device)\n",
        "        hidden, cell = self.encoder(source)\n",
        "        # hidden.shape = (num_layers, batch_size, hidden_size)\n",
        "        # cell.shape = (num_layers, batch_size, hidden_size)\n",
        "        x = target[:, 0]\n",
        "        # x.shape = (batch_size)\n",
        "        for t in range(1, target_len):\n",
        "            output, hidden, cell = self.decoder(x, hidden, cell)\n",
        "            # output.shape = (batch_size, target_vocab_size)\n",
        "            outputs[:, t] = output\n",
        "            best_guess = output.argmax(1)\n",
        "            x = target[:, t] if random.random() < teacher_forcing_ratio else best_guess\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "OOV95ro2mB8v"
      },
      "outputs": [],
      "source": [
        "# encoder hyperparameters\n",
        "input_size_encoder = len(dataset.vocab.word2idx)\n",
        "encoder_embedding_size = 200\n",
        "hidden_size = 128\n",
        "num_layers = 2\n",
        "# define the encoder\n",
        "encoder = Encoder(input_size_encoder, encoder_embedding_size, hidden_size, num_layers).to(device)\n",
        "# decoder hyperparameters\n",
        "input_size_decoder = len(dataset.vocab.word2idx)\n",
        "output_size = len(dataset.vocab.word2idx)\n",
        "decoder_embedding_size = 200\n",
        "hidden_size = 128\n",
        "num_layers = 2\n",
        "# define the decoder\n",
        "decoder = Decoder(input_size_decoder, decoder_embedding_size, hidden_size, output_size, num_layers).to(device)\n",
        "num_epochs = 25\n",
        "learning_rate = 1e-3\n",
        "# initialize the network\n",
        "encoder_net = Encoder(input_size_encoder, encoder_embedding_size, hidden_size, num_layers).to(device)\n",
        "decoder_net = Decoder(input_size_decoder, decoder_embedding_size, hidden_size, output_size, num_layers).to(device)\n",
        "model = Seq2Seq(encoder_net, decoder_net).to(device)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=dataset.vocab.word2idx['<pad>'])\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "n9bR1WYkmB8w"
      },
      "outputs": [],
      "source": [
        "# define a function that takes a tensor of indices and returns a string and removes pad and end and start tokens\n",
        "def tensor2string(tensor):\n",
        "    # tensor.shape = (seq_len)\n",
        "    words = [dataset.vocab.idx2word[idx.item()] for idx in tensor]\n",
        "    words = [word for word in words if word not in ['<pad>', '<sos>', '<eos>']]\n",
        "    return ' '.join(words)\n",
        "\n",
        "# define a function that generates a verse\n",
        "def generate_verse(model, source, device, tensor2string, max_len=20):\n",
        "    source = source.unsqueeze(0)\n",
        "    model.eval()\n",
        "    # dont forget to move to device\n",
        "    with torch.no_grad():\n",
        "        hidden, cell = model.encoder(source.to(device))\n",
        "        # hidden.shape = (num_layers, batch_size, hidden_size)\n",
        "        # cell.shape = (num_layers, batch_size, hidden_size)\n",
        "        x = torch.tensor([dataset.vocab.word2idx['<sos>']]).to(device)\n",
        "        outputs = []\n",
        "        for t in range(max_len):\n",
        "            output, hidden, cell = model.decoder(x, hidden, cell)\n",
        "            # output.shape = (1, output_size)\n",
        "            best_guess = output.argmax(1)\n",
        "            outputs.append(best_guess.item())\n",
        "            x = best_guess\n",
        "            if best_guess.item() == dataset.vocab.word2idx['<eos>']:\n",
        "                break\n",
        "    return tensor2string(torch.tensor(outputs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "HLN3HUVBmB8x"
      },
      "outputs": [],
      "source": [
        "# define a function that trains the model\n",
        "def train(model, train_loader, val_loader, criterion, optimizer, num_epochs, device, generate_verse, tensor2string):\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    train_accuracies = []\n",
        "    val_accuracies = []\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loss = 0\n",
        "        train_accuracy = 0\n",
        "        idx = random.randint(0, len(train_dataset))\n",
        "        verse = train_dataset[idx][0].to(device)\n",
        "        print(generate_verse(model, verse, tensor2string=tensor2string, device=device))\n",
        "        model.train()\n",
        "        for (source, target) in train_loader:\n",
        "            source = source.to(device)\n",
        "            target = target.to(device)\n",
        "            outputs = model(source, target)\n",
        "            # outputs.shape = (batch_size, target_seq_len, output_size)\n",
        "            outputs = outputs[:, 1:].reshape(-1, outputs.shape[2])\n",
        "            # outputs.shape = (batch_size * target_seq_len, output_size)\n",
        "            target = target[:, 1:].reshape(-1)\n",
        "            # target.shape = (batch_size * target_seq_len)\n",
        "            loss = criterion(outputs, target)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "            top_p, top_class = outputs.topk(1, dim=1)\n",
        "            # top_p.shape = (batch_size * target_seq_len, 1)\n",
        "            # top_class.shape = (batch_size * target_seq_len, 1)\n",
        "            equals = top_class == target.view(*top_class.shape)\n",
        "            # equals.shape = (batch_size * target_seq_len, 1)\n",
        "            train_accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
        "        train_losses.append(train_loss / len(train_loader))\n",
        "        train_accuracies.append(train_accuracy / len(train_loader))\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        val_accuracy = 0\n",
        "        with torch.no_grad():\n",
        "            for (source, target) in val_loader:\n",
        "                source = source.to(device)\n",
        "                target = target.to(device)\n",
        "                outputs = model(source, target)\n",
        "                # outputs.shape = (batch_size, target_seq_len, output_size)\n",
        "                outputs = outputs[:, 1:].reshape(-1, outputs.shape[2])\n",
        "                # outputs.shape = (batch_size * target_seq_len, output_size)\n",
        "                target = target[:, 1:].reshape(-1)\n",
        "                # target.shape = (batch_size * target_seq_len)\n",
        "                loss = criterion(outputs, target)\n",
        "                val_loss += loss.item()\n",
        "                top_p, top_class = outputs.topk(1, dim=1)\n",
        "                # top_p.shape = (batch_size * target_seq_len, 1)\n",
        "                # top_class.shape = (batch_size * target_seq_len, 1)\n",
        "                equals = top_class == target.view(*top_class.shape)\n",
        "                # equals.shape = (batch_size * target_seq_len, 1)\n",
        "                val_accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
        "        val_losses.append(val_loss / len(val_loader))\n",
        "        val_accuracies.append(val_accuracy / len(val_loader))\n",
        "        print(f'Epoch {epoch + 1}/{num_epochs} | Train Loss: {train_losses[-1]:.4f} | Train Accuracy: {train_accuracies[-1]:.4f} | Val Loss: {val_losses[-1]:.4f} | Val Accuracy: {val_accuracies[-1]:.4f}')\n",
        "    return train_losses, val_losses, train_accuracies, val_accuracies"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses, val_losses, train_accuracies, val_accuracies = train(model, train_loader, test_loader, criterion, optimizer, num_epochs, device, generate_verse, tensor2string)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPx2Q4M6ICR0",
        "outputId": "8983e164-7e99-4061-c615-7f11bc7d9399"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "کاه مراست مراست مراست بروها چرپ چرپ نابخردان نابخردان نماندش نماندش زآهن دمساز دمساز بیور بیور بگریستی بکنده سپیدش روشنک\n",
            "Epoch 1/25 | Train Loss: 5.9711 | Train Accuracy: 0.1225 | Val Loss: 5.7113 | Val Accuracy: 0.1315\n",
            "چو تا به از به <unk> <unk> <unk> که از از از از به <unk> به راه بود\n",
            "Epoch 2/25 | Train Loss: 5.5815 | Train Accuracy: 0.1348 | Val Loss: 5.5157 | Val Accuracy: 0.1394\n",
            "چو گفت کای شاه <unk> <unk> که از <unk> را به راه بود بود\n",
            "Epoch 3/25 | Train Loss: 5.3898 | Train Accuracy: 0.1426 | Val Loss: 5.3576 | Val Accuracy: 0.1463\n",
            "چو گفت به نزدیک شاه <unk> <unk> که از <unk> از داد یاد کرد جفت جفت\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(train_losses, label='train losses')\n",
        "plt.plot(val_losses, label='val losses')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.plot(train_accuracies, label='train accs')\n",
        "plt.plot(val_accuracies, label='val accs')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JAlvLPELXHKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To generate verses I only select those generated verses that have unique words in them and their length is more than 12"
      ],
      "metadata": {
        "id": "N8Du_GENXDVi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define a function that takes a tensor of indices and returns a string and removes pad and end and start tokens\n",
        "def tensor2string_unk(tensor):\n",
        "    # tensor.shape = (seq_len)\n",
        "    words = [dataset.vocab.idx2word[idx.item()] for idx in tensor]\n",
        "    words = [word for word in words if word not in ['<pad>', '<sos>', '<eos>', '<unk>']]\n",
        "    return ' '.join(words)\n",
        "print(\"Some Generated Verses: \")\n",
        "i = 0\n",
        "while not i == 10:\n",
        "  idx = random.randint(0, len(train_dataset))\n",
        "  verse = train_dataset[idx][0].to(device)\n",
        "  generated = generate_verse(model, verse, tensor2string=tensor2string_unk, device=device)\n",
        "  if len(generated.split()) > 12:\n",
        "    counts = Counter(generated.split())\n",
        "    counts = sorted(counts.items(), key=lambda x: x[1], reverse=True)\n",
        "    if counts[0][1] == 1:\n",
        "      i += 1\n",
        "      print(generated)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBflKC3bUmK2",
        "outputId": "0d2ced37-ad2a-459e-94c2-d322a303ebaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Some Generated Verses: \n",
            "کنون چون نشستیم با او که بر ما ربودی همی پشت گام پرند\n",
            "چو از دور دیدند بر همی رفت با او به جای نو گام زن\n",
            "سیاوش بدو گفت کای شهریار که من نیاید به کار زار سیر آر تاو\n",
            "چنین گفت با شاه ایران که ای نامداران گردان من سخن در گمان یادگار بگیر را بخوان\n",
            "چو از پیش او شد به بر آن بگشاد لب را بکشت جفت\n",
            "پس آگاهی آمد به ایران سپاه که از خونشان شد آوردگاه سیاه آمدند\n",
            "یکی نیزه انداخت بر گردنش به ابر اندر آورده روی زمین برزدند زدند\n",
            "بگویم ترا هرچ گفتی بطوس به از تیرگیها بیفروزدش رنگ بوی مست جوی چنگ\n",
            "بدو گفت بهرام کای شهریار که من نیاید به کار زار سیر آر خار خو\n",
            "چو من بگذرم زین سپنجی سرای که تو را باشدت رهنمای خدای نشست دست پای\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ytn4TkOnYiU"
      },
      "outputs": [],
      "source": [
        "# define another encoder with Bidirectional GRU\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size, embedding_size, hidden_size, num_layers, p_drop=0.1):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "        self.gru = nn.GRU(embedding_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
        "        self.dropout = nn.Dropout(p_drop)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x.shape = (batch_size, seq_len)\n",
        "        embedding = self.dropout(self.embedding(x))\n",
        "        # embedding.shape = (batch_size, seq_len, embedding_size)\n",
        "        outputs, hidden = self.gru(embedding)\n",
        "        # outputs.shape = (batch_size, seq_len, hidden_size * 2)\n",
        "        # hidden.shape = (num_layers * 2, batch_size, hidden_size)\n",
        "        return hidden\n",
        "\n",
        "# define decoder with bidirectional GRU\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers, p_drop=0.1):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.embedding = encoder.embedding\n",
        "        self.rnn = nn.GRU(embedding_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
        "        self.fc = nn.Linear(hidden_size * 2, output_size)  # since bidirectional, so multiply by 2\n",
        "        self.dropout = nn.Dropout(p_drop)\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        # x.shape = (batch_size, 1)\n",
        "        x = x.unsqueeze(1)\n",
        "        # x.shape = (batch_size, 1, 1)\n",
        "        embedding = self.dropout(self.embedding(x))\n",
        "        # embedding.shape = (batch_size, 1, embedding_size)\n",
        "        outputs, hidden = self.rnn(embedding, hidden)\n",
        "        # outputs.shape = (batch_size, 1, hidden_size * 2)  # since bidirectional, so hidden_size * 2\n",
        "        # hidden.shape = (num_layers * 2, batch_size, hidden_size)  # since bidirectional, so num_layers * 2\n",
        "        predictions = self.fc(outputs)\n",
        "        # predictions.shape = (batch_size, 1, output_size)\n",
        "        predictions = predictions.squeeze(1)\n",
        "        # predictions.shape = (batch_size, output_size)\n",
        "        return predictions, hidden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9zzrUjLI-SiG"
      },
      "outputs": [],
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, source, target, teacher_forcing_ratio=0.5):\n",
        "        # source.shape = (batch_size, source_seq_len)\n",
        "        # target.shape = (batch_size, target_seq_len)\n",
        "        batch_size = source.shape[0]\n",
        "        target_len = target.shape[1]\n",
        "        target_vocab_size = len(dataset.vocab.word2idx)\n",
        "        outputs = torch.zeros(batch_size, target_len, target_vocab_size).to(device)\n",
        "        hidden = self.encoder(source)\n",
        "        # hidden.shape = (batch_size, 2*hidden_size)\n",
        "        x = target[:, 0]\n",
        "        # x.shape = (batch_size)\n",
        "        for t in range(1, target_len):\n",
        "            output, hidden = self.decoder(x, hidden)\n",
        "            # output.shape = (batch_size, target_vocab_size)\n",
        "            outputs[:, t] = output\n",
        "            best_guess = output.argmax(1)\n",
        "            x = target[:, t] if random.random() < teacher_forcing_ratio else best_guess\n",
        "        return outputs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-SVMBPKm-SiH"
      },
      "outputs": [],
      "source": [
        "# hyperparameters\n",
        "input_size_encoder = len(dataset.vocab.word2idx)\n",
        "encoder_embedding_size = 200\n",
        "hidden_size = 128\n",
        "num_layers = 2\n",
        "# define the encoder\n",
        "encoder = Encoder(input_size_encoder, encoder_embedding_size, hidden_size, num_layers).to(device)\n",
        "# hyperparameters\n",
        "input_size_decoder = len(dataset.vocab.word2idx)\n",
        "output_size = len(dataset.vocab.word2idx)\n",
        "decoder_embedding_size = 200\n",
        "hidden_size = 128\n",
        "num_layers = 2\n",
        "num_epochs = 25\n",
        "# define the decoder\n",
        "decoder = Decoder(input_size_decoder, decoder_embedding_size, hidden_size, output_size, num_layers).to(device)\n",
        "model = Seq2Seq(encoder, decoder).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=dataset.vocab.word2idx['<pad>'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define a function that generates a verse for gru model\n",
        "def generate_verse_gru(model, source, device, tensor2string, max_len=20):\n",
        "    source = source.unsqueeze(0)\n",
        "    model.eval()\n",
        "    # dont forget to move to device\n",
        "    with torch.no_grad():\n",
        "        hidden = model.encoder(source.to(device))\n",
        "        # hidden.shape = (num_layers, batch_size, hidden_size)\n",
        "        # cell.shape = (num_layers, batch_size, hidden_size)\n",
        "        x = torch.tensor([dataset.vocab.word2idx['<sos>']]).to(device)\n",
        "        outputs = []\n",
        "        for t in range(max_len):\n",
        "            output, hidden = model.decoder(x, hidden)\n",
        "            # output.shape = (1, output_size)\n",
        "            best_guess = output.argmax(1)\n",
        "            outputs.append(best_guess.item())\n",
        "            x = best_guess\n",
        "            if best_guess.item() == dataset.vocab.word2idx['<eos>']:\n",
        "                break\n",
        "    return tensor2string(torch.tensor(outputs))"
      ],
      "metadata": {
        "id": "NofHrnyya_Q2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SnjsZFJk-SiI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d3a12b2-7a82-4cf9-8a23-b0c4f55b8bac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "فرهنگیان گرسیوزست زکار میش تنگست سرافگنده سرافگنده سخنهای افروزش افروزش کشیدندش کشیدندش پیمانت رستمت رخساره محمد کشیدندش رخساره کمست بسازند\n"
          ]
        }
      ],
      "source": [
        "train_losses, val_losses, train_accuracies, val_accuracies = train(model, train_loader, test_loader, criterion, optimizer, num_epochs, device, generate_verse_gru, tensor2string)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define a function that takes a tensor of indices and returns a string and removes pad and end and start tokens\n",
        "def tensor2string_unk(tensor):\n",
        "    # tensor.shape = (seq_len)\n",
        "    words = [dataset.vocab.idx2word[idx.item()] for idx in tensor]\n",
        "    words = [word for word in words if word not in ['<pad>', '<sos>', '<eos>', '<unk>']]\n",
        "    return ' '.join(words)\n",
        "print(\"Some Generated Verses: \")\n",
        "i = 0\n",
        "while not i == 10:\n",
        "  idx = random.randint(0, len(train_dataset))\n",
        "  verse = train_dataset[idx][0].to(device)\n",
        "  generated = generate_verse_gru(model, verse, tensor2string=tensor2string_unk device=device)\n",
        "  if len(generated.split()) > 12:\n",
        "    counts = Counter(generated.split())\n",
        "    counts = sorted(counts.items(), key=lambda x: x[1], reverse=True)\n",
        "    if counts[0][1] == 1:\n",
        "      i += 1\n",
        "      print(generated)"
      ],
      "metadata": {
        "id": "ETTeBnj-bpyx"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0 (tags/v3.9.0:9cf6752, Oct  5 2020, 15:34:40) [MSC v.1927 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "4fbe9694f7587329a2893969593bb646d9caf203732995a36644052b7dd475e8"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}